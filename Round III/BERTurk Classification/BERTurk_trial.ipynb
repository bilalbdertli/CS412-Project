{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10443025,"sourceType":"datasetVersion","datasetId":6463810},{"sourceId":10449169,"sourceType":"datasetVersion","datasetId":6467892},{"sourceId":10451357,"sourceType":"datasetVersion","datasetId":6469505}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ViralLab/TurkishBERTweet.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:10.610517Z","iopub.execute_input":"2025-01-12T16:40:10.610802Z","iopub.status.idle":"2025-01-12T16:40:11.781273Z","shell.execute_reply.started":"2025-01-12T16:40:10.610779Z","shell.execute_reply":"2025-01-12T16:40:11.780279Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'TurkishBERTweet'...\nremote: Enumerating objects: 1259, done.\u001b[K\nremote: Counting objects: 100% (759/759), done.\u001b[K\nremote: Compressing objects: 100% (469/469), done.\u001b[K\nremote: Total 1259 (delta 423), reused 621 (delta 290), pack-reused 500 (from 1)\u001b[K\nReceiving objects: 100% (1259/1259), 5.06 MiB | 31.00 MiB/s, done.\nResolving deltas: 100% (648/648), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install peft \n!pip install transformers\n!pip install urlextract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:11.782626Z","iopub.execute_input":"2025-01-12T16:40:11.782952Z","iopub.status.idle":"2025-01-12T16:40:27.075651Z","shell.execute_reply.started":"2025-01-12T16:40:11.782924Z","shell.execute_reply":"2025-01-12T16:40:27.074546Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\nCollecting huggingface-hub>=0.25.0 (from peft)\n  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, peft\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\nSuccessfully installed huggingface-hub-0.27.1 peft-0.14.0\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nCollecting urlextract\n  Downloading urlextract-1.9.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.10)\nCollecting uritools (from urlextract)\n  Downloading uritools-4.0.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from urlextract) (4.3.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.16.1)\nDownloading urlextract-1.9.0-py3-none-any.whl (21 kB)\nDownloading uritools-4.0.3-py3-none-any.whl (10 kB)\nInstalling collected packages: uritools, urlextract\nSuccessfully installed uritools-4.0.3 urlextract-1.9.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys\nsys.path.append('./TurkishBERTweet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:27.077730Z","iopub.execute_input":"2025-01-12T16:40:27.078033Z","iopub.status.idle":"2025-01-12T16:40:27.081642Z","shell.execute_reply.started":"2025-01-12T16:40:27.078011Z","shell.execute_reply":"2025-01-12T16:40:27.080826Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from Preprocessor import preprocess\n\ntext = \"\"\"Lab'ımıza \"viral\" adını verdik çünkü amacımız disiplinler arası sınırları aşmak ve aralarında yeni bağlantılar kurmak! 🔬 #ViralLab\nhttps://varollab.com/\"\"\"\n\npreprocessed_text = preprocess(text)\nprint(preprocessed_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:27.082772Z","iopub.execute_input":"2025-01-12T16:40:27.083039Z","iopub.status.idle":"2025-01-12T16:40:27.183824Z","shell.execute_reply.started":"2025-01-12T16:40:27.083010Z","shell.execute_reply":"2025-01-12T16:40:27.183174Z"}},"outputs":[{"name":"stdout","text":"lab'ımıza \"viral\" adını verdik çünkü amacımız disiplinler arası sınırları aşmak ve aralarında yeni bağlantılar kurmak! <emoji> mikroskop </emoji> <hashtag> virallab </hashtag> <http> varollab.com </http>\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom Preprocessor import preprocess\n\ntokenizer = AutoTokenizer.from_pretrained(\"VRLLab/TurkishBERTweet\")\nturkishBERTweet = AutoModelForSequenceClassification.from_pretrained(\"VRLLab/TurkishBERTweet\", num_labels=10)\n\ntext = \"\"\"Lab'ımıza \"viral\" adını verdik çünkü amacımız disiplinler arası sınırları aşmak ve aralarında yeni bağlantılar kurmak! 💥🔬 #ViralLab #DisiplinlerArası #YenilikçiBağlantılar\"\"\"\n\npreprocessed_text = preprocess(text)\ninput_ids = torch.tensor([tokenizer.encode(preprocessed_text)])\n\nwith torch.no_grad():\n    features = turkishBERTweet(input_ids)  # Models outputs are now tuples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:27.184640Z","iopub.execute_input":"2025-01-12T16:40:27.184920Z","iopub.status.idle":"2025-01-12T16:40:38.550444Z","shell.execute_reply.started":"2025-01-12T16:40:27.184888Z","shell.execute_reply":"2025-01-12T16:40:38.549704Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5f48d7679b4008949249fe7d6004c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.88M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21878bad5ecb474fb6d56521aa01a355"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.19M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1bde6a6ec6743028adbfc4cb3c6d4f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d491b24823149a39bf3298252fdd027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7aaf243fd174fb6b82e7e046606e3a4"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1aeffd745f4816937768a56e04e7b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/652M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28684855ccae4f79865c175e4aca4cc3"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at VRLLab/TurkishBERTweet and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Data Preprocessing and Cleaning","metadata":{}},{"cell_type":"code","source":"!pip install nltk\nimport numpy as np\nimport pandas as pd\nimport gzip\nimport json\n\nfrom pprint import pprint\n#@title Turkish StopWords\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('punkt_tab')\nturkish_stopwords = stopwords.words('turkish')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:38.551329Z","iopub.execute_input":"2025-01-12T16:40:38.551682Z","iopub.status.idle":"2025-01-12T16:40:43.399568Z","shell.execute_reply.started":"2025-01-12T16:40:38.551660Z","shell.execute_reply":"2025-01-12T16:40:43.398767Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.16.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_classification_df = pd.read_csv(\"/kaggle/input/cs412-dataset/train-classification.csv\")\ntrain_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n\n# Unifying labels\ntrain_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\nusername2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:43.400378Z","iopub.execute_input":"2025-01-12T16:40:43.400857Z","iopub.status.idle":"2025-01-12T16:40:43.432652Z","shell.execute_reply.started":"2025-01-12T16:40:43.400833Z","shell.execute_reply":"2025-01-12T16:40:43.431926Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_data_path = \"/kaggle/input/cs412-dataset/training-dataset.jsonl\"\n\nusername2posts_train = dict()\nusername2profile_train = dict()\n\nusername2posts_test = dict()\nusername2profile_test = dict()\n\n\nwith open(train_data_path, \"rt\") as fh:\n  for line in fh:\n    sample = json.loads(line)\n\n    profile = sample[\"profile\"] # Everything is under here except for posts\n    username = profile[\"username\"] #Get the username\n    if username in username2_category: #We already know the category for this user.\n      # train data info\n      username2posts_train[username] = sample[\"posts\"]\n      username2profile_train[username] = profile #Add the profile data into this dictionary\n\n\n    else:\n      # it is test data info\n      username2posts_test[username] = sample[\"posts\"]\n      username2profile_test[username] = profile\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:43.433478Z","iopub.execute_input":"2025-01-12T16:40:43.433709Z","iopub.status.idle":"2025-01-12T16:40:51.539525Z","shell.execute_reply.started":"2025-01-12T16:40:43.433689Z","shell.execute_reply":"2025-01-12T16:40:51.538815Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Profile Dataframe\ntrain_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\ntest_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n\ntrain_profile_df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.541858Z","iopub.execute_input":"2025-01-12T16:40:51.542120Z","iopub.status.idle":"2025-01-12T16:40:51.720189Z","shell.execute_reply.started":"2025-01-12T16:40:51.542075Z","shell.execute_reply":"2025-01-12T16:40:51.719465Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"     username          id    full_name  \\\n0  deparmedya  3170700063  Depar Medya   \n1  kafesfirin   266439571  KAFES FIRIN   \n\n                                           biography   category_name  \\\n0           #mediaplanning #mediabuying #sosyalmedya  Local business   \n1  📍Söğütözü📍FTZ AVM\\n🛒Ankara macro▲center v...           Brand   \n\n  post_count follower_count following_count is_business_account is_private  \\\n0       None           1167             192                True      False   \n1       None          11997              17                True      False   \n\n   ... business_category_name overall_category_name category_enum  \\\n0  ...                   None                  None         LOCAL   \n1  ...                   None                  None         BRAND   \n\n  is_verified_by_mv4b is_regulated_c18  \\\n0               False            False   \n1               False            False   \n\n                                     profile_pic_url should_show_category  \\\n0  https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....                 True   \n1  https://instagram.fada1-13.fna.fbcdn.net/v/t51...                 True   \n\n  should_show_public_contacts show_account_transparency_details  \\\n0                        True                              True   \n1                        True                              True   \n\n                              profile_picture_base64  \n0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n\n[2 rows x 44 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>id</th>\n      <th>full_name</th>\n      <th>biography</th>\n      <th>category_name</th>\n      <th>post_count</th>\n      <th>follower_count</th>\n      <th>following_count</th>\n      <th>is_business_account</th>\n      <th>is_private</th>\n      <th>...</th>\n      <th>business_category_name</th>\n      <th>overall_category_name</th>\n      <th>category_enum</th>\n      <th>is_verified_by_mv4b</th>\n      <th>is_regulated_c18</th>\n      <th>profile_pic_url</th>\n      <th>should_show_category</th>\n      <th>should_show_public_contacts</th>\n      <th>show_account_transparency_details</th>\n      <th>profile_picture_base64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>deparmedya</td>\n      <td>3170700063</td>\n      <td>Depar Medya</td>\n      <td>#mediaplanning #mediabuying #sosyalmedya</td>\n      <td>Local business</td>\n      <td>None</td>\n      <td>1167</td>\n      <td>192</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>LOCAL</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kafesfirin</td>\n      <td>266439571</td>\n      <td>KAFES FIRIN</td>\n      <td>📍Söğütözü📍FTZ AVM\\n🛒Ankara macro▲center v...</td>\n      <td>Brand</td>\n      <td>None</td>\n      <td>11997</td>\n      <td>17</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>BRAND</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fada1-13.fna.fbcdn.net/v/t51...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 44 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"test_profile_df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.721539Z","iopub.execute_input":"2025-01-12T16:40:51.721751Z","iopub.status.idle":"2025-01-12T16:40:51.735806Z","shell.execute_reply.started":"2025-01-12T16:40:51.721733Z","shell.execute_reply":"2025-01-12T16:40:51.735033Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                     username          id                    full_name  \\\n0              beyazyakaliyiz  8634457436           Selam Beyaz Yakalı   \n1  totalenergies_istasyonlari  7066643793  TotalEnergies İstasyonları   \n\n                                           biography   category_name  \\\n0        Beyaz yakalıların dünyasına hoşgeldiniz 😀😀😀   Personal blog   \n1  TotalEnergies İstasyonları resmi Instagram hes...  Energy Company   \n\n  post_count follower_count following_count is_business_account is_private  \\\n0       None           1265             665                True      False   \n1       None          28025               4                True      False   \n\n   ... business_category_name overall_category_name   category_enum  \\\n0  ...                   None                  None   PERSONAL_BLOG   \n1  ...                   None                  None  ENERGY_COMPANY   \n\n  is_verified_by_mv4b is_regulated_c18  \\\n0               False            False   \n1               False            False   \n\n                                     profile_pic_url should_show_category  \\\n0  https://instagram.fist6-1.fna.fbcdn.net/v/t51....                 True   \n1  https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....                 True   \n\n  should_show_public_contacts show_account_transparency_details  \\\n0                        True                              True   \n1                        True                              True   \n\n                              profile_picture_base64  \n0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n\n[2 rows x 44 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>id</th>\n      <th>full_name</th>\n      <th>biography</th>\n      <th>category_name</th>\n      <th>post_count</th>\n      <th>follower_count</th>\n      <th>following_count</th>\n      <th>is_business_account</th>\n      <th>is_private</th>\n      <th>...</th>\n      <th>business_category_name</th>\n      <th>overall_category_name</th>\n      <th>category_enum</th>\n      <th>is_verified_by_mv4b</th>\n      <th>is_regulated_c18</th>\n      <th>profile_pic_url</th>\n      <th>should_show_category</th>\n      <th>should_show_public_contacts</th>\n      <th>show_account_transparency_details</th>\n      <th>profile_picture_base64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>beyazyakaliyiz</td>\n      <td>8634457436</td>\n      <td>Selam Beyaz Yakalı</td>\n      <td>Beyaz yakalıların dünyasına hoşgeldiniz 😀😀😀</td>\n      <td>Personal blog</td>\n      <td>None</td>\n      <td>1265</td>\n      <td>665</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>PERSONAL_BLOG</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fist6-1.fna.fbcdn.net/v/t51....</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>totalenergies_istasyonlari</td>\n      <td>7066643793</td>\n      <td>TotalEnergies İstasyonları</td>\n      <td>TotalEnergies İstasyonları resmi Instagram hes...</td>\n      <td>Energy Company</td>\n      <td>None</td>\n      <td>28025</td>\n      <td>4</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>ENERGY_COMPANY</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 44 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print(\"Profile DataFrame Columns:\", train_profile_df.columns.tolist())\nprint(\"Count is:\", len(train_profile_df.columns))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.736622Z","iopub.execute_input":"2025-01-12T16:40:51.736873Z","iopub.status.idle":"2025-01-12T16:40:51.749845Z","shell.execute_reply.started":"2025-01-12T16:40:51.736853Z","shell.execute_reply":"2025-01-12T16:40:51.749077Z"}},"outputs":[{"name":"stdout","text":"Profile DataFrame Columns: ['username', 'id', 'full_name', 'biography', 'category_name', 'post_count', 'follower_count', 'following_count', 'is_business_account', 'is_private', 'is_verified', 'highlight_reel_count', 'bio_links', 'entities', 'ai_agent_type', 'fb_profile_biolink', 'restricted_by_viewer', 'country_block', 'eimu_id', 'external_url', 'fbid', 'has_clips', 'hide_like_and_view_counts', 'is_professional_account', 'is_supervision_enabled', 'is_guardian_of_viewer', 'is_supervised_by_viewer', 'is_supervised_user', 'is_embeds_disabled', 'is_joined_recently', 'business_address_json', 'business_contact_method', 'business_email', 'business_phone_number', 'business_category_name', 'overall_category_name', 'category_enum', 'is_verified_by_mv4b', 'is_regulated_c18', 'profile_pic_url', 'should_show_category', 'should_show_public_contacts', 'show_account_transparency_details', 'profile_picture_base64']\nCount is: 44\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"username2posts_train[\"deparmedya\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.750548Z","iopub.execute_input":"2025-01-12T16:40:51.750764Z","iopub.status.idle":"2025-01-12T16:40:51.767557Z","shell.execute_reply.started":"2025-01-12T16:40:51.750738Z","shell.execute_reply":"2025-01-12T16:40:51.766881Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'caption': 'Cumhuriyetimizin 100.yılı kutlu olsun♾️🇹🇷',\n 'comments_count': 0,\n 'id': '17990918969458720',\n 'like_count': 6,\n 'media_type': 'IMAGE',\n 'media_url': 'https://scontent-sof1-2.cdninstagram.com/v/t51.29350-15/396342908_267936919574308_4264417069827989599_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=c4dd86&_nc_ohc=IynXuQSoOT8AX9RSy20&_nc_ht=scontent-sof1-2.cdninstagram.com&edm=AL-3X8kEAAAA&oh=00_AfA8OKAM0MY9tqg6dw8C8I5TJp4SHPBp-VlNXrFAh2agqg&oe=6563581C',\n 'timestamp': '2023-10-29 09:12:30'}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"list(username2posts_train[\"deparmedya\"][0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.768325Z","iopub.execute_input":"2025-01-12T16:40:51.768575Z","iopub.status.idle":"2025-01-12T16:40:51.782313Z","shell.execute_reply.started":"2025-01-12T16:40:51.768546Z","shell.execute_reply":"2025-01-12T16:40:51.781541Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['caption',\n 'comments_count',\n 'id',\n 'like_count',\n 'media_type',\n 'media_url',\n 'timestamp']"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"username = \"deparmedya\"\nuser_profile = username2profile_train.get(username, {})\nbiography = user_profile.get(\"biography\", \"\")\nprint(preprocess(biography))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.783214Z","iopub.execute_input":"2025-01-12T16:40:51.783491Z","iopub.status.idle":"2025-01-12T16:40:51.797100Z","shell.execute_reply.started":"2025-01-12T16:40:51.783464Z","shell.execute_reply":"2025-01-12T16:40:51.796320Z"}},"outputs":[{"name":"stdout","text":"<hashtag> mediaplanning </hashtag> <hashtag> mediabuying </hashtag> <hashtag> sosyalmedya </hashtag>\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nimport emoji\nfrom scipy.sparse import hstack\n\n\n# to keep the label order\ntrain_usernames = []\ntrain_caption_bio_combined = []\ntrain_captions = []\ntrain_bio = []\n\nmax_total_tokens_for_user_captions = 0 # To keep the total number of tokens, if > 128, then we need to do something.\nfor username, posts in username2posts_train.items():\n  train_usernames.append(username)\n  user_profile = username2profile_train.get(username, {})\n  user_biography = user_profile.get(\"biography\") or \"\"\n  user_biography = preprocess(user_biography) #using the preprocessor of the model\n  train_bio.append(user_biography)\n  # aggregating the posts per user\n  cleaned_captions = []\n  for post in posts:\n    post_caption = post.get(\"caption\", \"\")\n    if post_caption is None:\n      continue\n    post_caption = preprocess(post_caption)\n    if post_caption != \"\":\n      cleaned_captions.append(post_caption)\n  user_post_captions = \" \".join(cleaned_captions)\n  if not user_post_captions.strip():\n    print(\"User \" + username + \" from training has empty captions.\")\n\n  train_captions.append(user_post_captions)\n\ny_train = [username2_category.get(uname, \"NA\").lower() for uname in train_usernames]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.797775Z","iopub.execute_input":"2025-01-12T16:40:51.797987Z","iopub.status.idle":"2025-01-12T16:45:00.855686Z","shell.execute_reply.started":"2025-01-12T16:40:51.797969Z","shell.execute_reply":"2025-01-12T16:45:00.855000Z"}},"outputs":[{"name":"stdout","text":"User birguzeladam from training has empty captions.\nUser touchdownistanbul from training has empty captions.\nUser mks_kilit_sistemleri from training has empty captions.\nUser belediyesikose from training has empty captions.\nUser esqtekstil from training has empty captions.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"len(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.856536Z","iopub.execute_input":"2025-01-12T16:45:00.856824Z","iopub.status.idle":"2025-01-12T16:45:00.861728Z","shell.execute_reply.started":"2025-01-12T16:45:00.856795Z","shell.execute_reply":"2025-01-12T16:45:00.861037Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"2741"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"train_captions[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.862443Z","iopub.execute_input":"2025-01-12T16:45:00.862708Z","iopub.status.idle":"2025-01-12T16:45:00.881615Z","shell.execute_reply.started":"2025-01-12T16:45:00.862689Z","shell.execute_reply":"2025-01-12T16:45:00.880991Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"cumhuriyetimizin 100.yılı kutlu olsun <emoji> sonsuzluk </emoji> <emoji> bayrak_tunus </emoji> oriflame duologi lansmanı <hashtag> isveçtengelengüzellik </hashtag> <hashtag> oriflameilesaçbakımdevrimi </hashtag> <hashtag> oriflameilesaçbakımdevrimi </hashtag> <emoji> sıkıştıran_el_koyu_ten_tonu </emoji> <emoji> sıkıştıran_el_koyu_ten_tonu </emoji> <hashtag> oriflameilesaçbakımdevrimi </hashtag> 07agustos’23 oriflameturkiye 07 agustos’23 <hashtag> oriflameturkiye </hashtag> <hashtag> duoloji </hashtag> oriflame <hashtag> duoloji </hashtag> muhteşem saçların sırrı <hashtag> duoloji </hashtag> oriflameturkiye goe elektirikli motorsiklet ile , sürdürülebilir bir yaşamın elçisi olun! <hashtag> goeilegeleceğeyönver </hashtag> <hashtag> goeilesürdürülebilirgelecek </hashtag> <hashtag> easytorideeasytolove </hashtag> goe_mobility <emoji> motosiklet </emoji> 7 haziran’23 <hashtag> yazamerhaba </hashtag> feridaistanbul 7 haziran’23 <hashtag> yazamerhaba </hashtag> feridaistanbul <hashtag> yazamerhaba </hashtag> <emoji> sıkıştıran_el_koyu_ten_tonu </emoji> <emoji> kiraz_çiçeği </emoji> feridacadde jumbopatisserie'nin 'edible art’ konseptiyle özel olarak hazırlanan tatlıları ve baci milano'nun şık ve renkli dünyasında kahvaltıdayız <hashtag> jumboturkiye </hashtag> easy to love, easy to ride <emoji> kırmızı_kalp </emoji> goe_mobility figamortr mustafa kemal atatürk'ü sevgi,saygı ve özlemle anıyoruz. notecosmetiqueturkiye <hashtag> event </hashtag> <hashtag> kendimenote </hashtag> notecosmetiqueturkiye otoshops outdoor çalışmaları otoshopsturkiye mad parfüm outdoor çalışmalarımız madparfumeurofficial <hashtag> açıkhavareklam </hashtag> <hashtag> letsgetmad </hashtag> notecosmetiqueturkiye <hashtag> kendimenote </hashtag> note cosmetique açıkhava <emoji> parıldıyor </emoji> note cosmetique etkinliğinden <emoji> balon </emoji> cumhuriyet bayramınız kutlu olsun <emoji> bayrak_tunus </emoji> geçmiş olsun türkiye <emoji> katlanmış_eller </emoji> kurban bayramınız kutlu olsun <emoji> gülen_yüz </emoji> “dünyada her şey kadının eseridir.” mustafa kemal atatürk sizin gibi güçlü, mücadeleci ve emekçi bir kadının bütün dünya kadınlarına örnek olması dileğiyle <emoji> kırmızı_kalp </emoji> 8 mart dünya emekçi kadınlar günü kutlu olsun. depar medya ekibi <hashtag> 8martdünyakadınlargünü </hashtag> öğretmenler günü kutlu olsun. <hashtag> 24kasımöğretmenlergünü </hashtag> <hashtag> deparmedya </hashtag> pruvada tek eksik siz’siniz. pruva.34 burcues <hashtag> deparmedya </hashtag> saygı ve özlemle anıyoruz... <hashtag> 10kasım </hashtag> <hashtag> atatürk </hashtag> geçmiş olsun i̇zmir <emoji> katlanmış_eller </emoji> dualarımız sizinle. cumhuriyetimiz bugün 97 yaşında! 29 ekim cumhuriyet bayramı’mız kutlu olsun! <emoji> bayrak_tunus </emoji> finlandiya'da şehrin kadına yönelik şiddet hakkında bir farkındalık kampanyası! helsinki’nin merkezinde yer alan havis amanda heykeli, şehrin en ikonik sanat eserlerinden biri olmasının yanı sıra talihsiz bir özelliğe de sahip. 100 yılı deviren heykel, sık sık şehirdeki kutlamaların ortasında kalıyor ve çoğunluğunu erkeklerin oluşturduğu insanların tırmanışlarına maruz kalıyor. yıkılma tehlikesi bulunan heykelin en kırılgan kısmı ise boyun bölgesi. ülkedeki şiddet mağdurlarına yardım eli uzatan nollalinja, bu yıl kadına yönelik şiddete karşı uluslararası mücadele ve dayanışma günü’nde havis amanda’ya bir boyunluk yerleştirdi. böylece, şehrin ikonik heykeli kadına yönelik şiddete karşı bir uyarı sembolüne dönüştü. türkiye vodafone vakfı, eğitime destek için herkesi twitter hesaplarını bağışlamaya davet ediyor! türkiye vodafone vakfı, dijital geleceğe hazır nesiller yetiştirilmesi hedefiyle habitat derneği işbirliğiyle hayata geçirdiği yarını kodlayanlar projesi kapsamında <hashtag> hesabımkitapolsun </hashtag> etiketiyle yeni bir sosyal medya kampanyası başlattı. çocukların eğitimine destek olmak amacıyla twitter üzerinden hayata geçirilen kitap bağışı kapsamında, <hashtag> hesabımkitapolsun </hashtag> etiketiyle tweet atan kullanıcılar, bir anlamda twitter hesaplarını bağışlamış olacak. <hashtag> hesabımkitapolsun </hashtag> etiketiyle tweet atan bir kullanıcının hesabındaki toplam kelime sayısına en yakın sayıda kelimeye sahip bir kitap, kullanıcı adına bir okula bağışlanacak. huawei watch gt 2'den hiç çıkarılmayacak saat! p smart 2019 ve p30 serisi akıllı telefonlarının reklamlarını türkiye’de çeken huawei türkiye, kampanyalarındaki yerel bakış açısını yeni nesil akıllı saati huawei watch gt 2 için hazırladığı reklam filmiyle sürdürüyor. “hiç çıkarma” adlı kampanya kapsamında watch gt 2 için hazırlanan filmde beyaz yakalı gençler üzerinden, watch gt 2’nin haftalarca süren pil performansına ve günlük hayatta sağladığı faydalara odaklanılıyor. beyaz yakalı genç profesyonellerin günlük süreçlerinin incelenmesinin ardından gözlemlenen trendlere uygun olarak hazırlanan filmde gençlerin hem yaşam asistanı hem sağlık takipçisi hem de kişisel antrenörü olan watch gt 2’yi takanlar, onu hiç çıkarmıyor.\""},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"train_bio[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.882304Z","iopub.execute_input":"2025-01-12T16:45:00.882511Z","iopub.status.idle":"2025-01-12T16:45:00.895339Z","shell.execute_reply.started":"2025-01-12T16:45:00.882487Z","shell.execute_reply":"2025-01-12T16:45:00.894705Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'<hashtag> mediaplanning </hashtag> <hashtag> mediabuying </hashtag> <hashtag> sosyalmedya </hashtag>'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"train_usernames[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.896010Z","iopub.execute_input":"2025-01-12T16:45:00.896257Z","iopub.status.idle":"2025-01-12T16:45:00.910866Z","shell.execute_reply.started":"2025-01-12T16:45:00.896237Z","shell.execute_reply":"2025-01-12T16:45:00.910079Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'deparmedya'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"categories = [\n    'mom and children',\n    'food',\n    'travel',\n    'gaming',\n    'fashion',\n    'health and lifestyle',\n    'tech',\n    'entertainment',\n    'sports',\n    'art'\n]\n\n# Create label2id and id2label\nlabel2id = {label: idx for idx, label in enumerate(categories)}\nid2label = {idx: label for idx, label in enumerate(categories)}\n\nprint(\"label2id:\", label2id)\nprint(\"id2label:\", id2label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.911662Z","iopub.execute_input":"2025-01-12T16:45:00.911868Z","iopub.status.idle":"2025-01-12T16:45:00.926307Z","shell.execute_reply.started":"2025-01-12T16:45:00.911849Z","shell.execute_reply":"2025-01-12T16:45:00.925508Z"}},"outputs":[{"name":"stdout","text":"label2id: {'mom and children': 0, 'food': 1, 'travel': 2, 'gaming': 3, 'fashion': 4, 'health and lifestyle': 5, 'tech': 6, 'entertainment': 7, 'sports': 8, 'art': 9}\nid2label: {0: 'mom and children', 1: 'food', 2: 'travel', 3: 'gaming', 4: 'fashion', 5: 'health and lifestyle', 6: 'tech', 7: 'entertainment', 8: 'sports', 9: 'art'}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"len(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.927080Z","iopub.execute_input":"2025-01-12T16:45:00.927353Z","iopub.status.idle":"2025-01-12T16:45:00.942077Z","shell.execute_reply.started":"2025-01-12T16:45:00.927334Z","shell.execute_reply":"2025-01-12T16:45:00.941493Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer\n)\nfrom datasets import Dataset\n\nfrom peft import (\n    PeftModel,\n    PeftConfig,\n)\n\ntexts = []\nfor bio, caption in zip(train_bio, train_captions):\n    combined_text = bio.strip() + \" \" + caption.strip()\n    texts.append(combined_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.942758Z","iopub.execute_input":"2025-01-12T16:45:00.943022Z","iopub.status.idle":"2025-01-12T16:45:09.188737Z","shell.execute_reply.started":"2025-01-12T16:45:00.943002Z","shell.execute_reply":"2025-01-12T16:45:09.187927Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"numeric_labels = [label2id[label_str] for label_str in y_train]\nlen(numeric_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:09.189594Z","iopub.execute_input":"2025-01-12T16:45:09.190109Z","iopub.status.idle":"2025-01-12T16:45:09.195714Z","shell.execute_reply.started":"2025-01-12T16:45:09.190071Z","shell.execute_reply":"2025-01-12T16:45:09.194946Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"2741"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"texts[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:09.196398Z","iopub.execute_input":"2025-01-12T16:45:09.196710Z","iopub.status.idle":"2025-01-12T16:45:09.216639Z","shell.execute_reply.started":"2025-01-12T16:45:09.196684Z","shell.execute_reply":"2025-01-12T16:45:09.216011Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"<hashtag> mediaplanning </hashtag> <hashtag> mediabuying </hashtag> <hashtag> sosyalmedya </hashtag> cumhuriyetimizin 100.yılı kutlu olsun <emoji> sonsuzluk </emoji> <emoji> bayrak_tunus </emoji> oriflame duologi lansmanı <hashtag> isveçtengelengüzellik </hashtag> <hashtag> oriflameilesaçbakımdevrimi </hashtag> <hashtag> oriflameilesaçbakımdevrimi </hashtag> <emoji> sıkıştıran_el_koyu_ten_tonu </emoji> <emoji> sıkıştıran_el_koyu_ten_tonu </emoji> <hashtag> oriflameilesaçbakımdevrimi </hashtag> 07agustos’23 oriflameturkiye 07 agustos’23 <hashtag> oriflameturkiye </hashtag> <hashtag> duoloji </hashtag> oriflame <hashtag> duoloji </hashtag> muhteşem saçların sırrı <hashtag> duoloji </hashtag> oriflameturkiye goe elektirikli motorsiklet ile , sürdürülebilir bir yaşamın elçisi olun! <hashtag> goeilegeleceğeyönver </hashtag> <hashtag> goeilesürdürülebilirgelecek </hashtag> <hashtag> easytorideeasytolove </hashtag> goe_mobility <emoji> motosiklet </emoji> 7 haziran’23 <hashtag> yazamerhaba </hashtag> feridaistanbul 7 haziran’23 <hashtag> yazamerhaba </hashtag> feridaistanbul <hashtag> yazamerhaba </hashtag> <emoji> sıkıştıran_el_koyu_ten_tonu </emoji> <emoji> kiraz_çiçeği </emoji> feridacadde jumbopatisserie'nin 'edible art’ konseptiyle özel olarak hazırlanan tatlıları ve baci milano'nun şık ve renkli dünyasında kahvaltıdayız <hashtag> jumboturkiye </hashtag> easy to love, easy to ride <emoji> kırmızı_kalp </emoji> goe_mobility figamortr mustafa kemal atatürk'ü sevgi,saygı ve özlemle anıyoruz. notecosmetiqueturkiye <hashtag> event </hashtag> <hashtag> kendimenote </hashtag> notecosmetiqueturkiye otoshops outdoor çalışmaları otoshopsturkiye mad parfüm outdoor çalışmalarımız madparfumeurofficial <hashtag> açıkhavareklam </hashtag> <hashtag> letsgetmad </hashtag> notecosmetiqueturkiye <hashtag> kendimenote </hashtag> note cosmetique açıkhava <emoji> parıldıyor </emoji> note cosmetique etkinliğinden <emoji> balon </emoji> cumhuriyet bayramınız kutlu olsun <emoji> bayrak_tunus </emoji> geçmiş olsun türkiye <emoji> katlanmış_eller </emoji> kurban bayramınız kutlu olsun <emoji> gülen_yüz </emoji> “dünyada her şey kadının eseridir.” mustafa kemal atatürk sizin gibi güçlü, mücadeleci ve emekçi bir kadının bütün dünya kadınlarına örnek olması dileğiyle <emoji> kırmızı_kalp </emoji> 8 mart dünya emekçi kadınlar günü kutlu olsun. depar medya ekibi <hashtag> 8martdünyakadınlargünü </hashtag> öğretmenler günü kutlu olsun. <hashtag> 24kasımöğretmenlergünü </hashtag> <hashtag> deparmedya </hashtag> pruvada tek eksik siz’siniz. pruva.34 burcues <hashtag> deparmedya </hashtag> saygı ve özlemle anıyoruz... <hashtag> 10kasım </hashtag> <hashtag> atatürk </hashtag> geçmiş olsun i̇zmir <emoji> katlanmış_eller </emoji> dualarımız sizinle. cumhuriyetimiz bugün 97 yaşında! 29 ekim cumhuriyet bayramı’mız kutlu olsun! <emoji> bayrak_tunus </emoji> finlandiya'da şehrin kadına yönelik şiddet hakkında bir farkındalık kampanyası! helsinki’nin merkezinde yer alan havis amanda heykeli, şehrin en ikonik sanat eserlerinden biri olmasının yanı sıra talihsiz bir özelliğe de sahip. 100 yılı deviren heykel, sık sık şehirdeki kutlamaların ortasında kalıyor ve çoğunluğunu erkeklerin oluşturduğu insanların tırmanışlarına maruz kalıyor. yıkılma tehlikesi bulunan heykelin en kırılgan kısmı ise boyun bölgesi. ülkedeki şiddet mağdurlarına yardım eli uzatan nollalinja, bu yıl kadına yönelik şiddete karşı uluslararası mücadele ve dayanışma günü’nde havis amanda’ya bir boyunluk yerleştirdi. böylece, şehrin ikonik heykeli kadına yönelik şiddete karşı bir uyarı sembolüne dönüştü. türkiye vodafone vakfı, eğitime destek için herkesi twitter hesaplarını bağışlamaya davet ediyor! türkiye vodafone vakfı, dijital geleceğe hazır nesiller yetiştirilmesi hedefiyle habitat derneği işbirliğiyle hayata geçirdiği yarını kodlayanlar projesi kapsamında <hashtag> hesabımkitapolsun </hashtag> etiketiyle yeni bir sosyal medya kampanyası başlattı. çocukların eğitimine destek olmak amacıyla twitter üzerinden hayata geçirilen kitap bağışı kapsamında, <hashtag> hesabımkitapolsun </hashtag> etiketiyle tweet atan kullanıcılar, bir anlamda twitter hesaplarını bağışlamış olacak. <hashtag> hesabımkitapolsun </hashtag> etiketiyle tweet atan bir kullanıcının hesabındaki toplam kelime sayısına en yakın sayıda kelimeye sahip bir kitap, kullanıcı adına bir okula bağışlanacak. huawei watch gt 2'den hiç çıkarılmayacak saat! p smart 2019 ve p30 serisi akıllı telefonlarının reklamlarını türkiye’de çeken huawei türkiye, kampanyalarındaki yerel bakış açısını yeni nesil akıllı saati huawei watch gt 2 için hazırladığı reklam filmiyle sürdürüyor. “hiç çıkarma” adlı kampanya kapsamında watch gt 2 için hazırlanan filmde beyaz yakalı gençler üzerinden, watch gt 2’nin haftalarca süren pil performansına ve günlük hayatta sağladığı faydalara odaklanılıyor. beyaz yakalı genç profesyonellerin günlük süreçlerinin incelenmesinin ardından gözlemlenen trendlere uygun olarak hazırlanan filmde gençlerin hem yaşam asistanı hem sağlık takipçisi hem de kişisel antrenörü olan watch gt 2’yi takanlar, onu hiç çıkarmıyor.\""},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"model_name = \"dbmdz/bert-base-turkish-uncased\"\n# model_name = \"dbmdz/bert-base-turkish-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=10,            # <-- your 10 labels\n    id2label=id2label,\n    label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:09.217423Z","iopub.execute_input":"2025-01-12T16:45:09.217709Z","iopub.status.idle":"2025-01-12T16:45:13.759700Z","shell.execute_reply.started":"2025-01-12T16:45:09.217681Z","shell.execute_reply":"2025-01-12T16:45:13.759067Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8d4cacc22944758bca395881bec0f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa7b18485b440f187076ffe21dac9fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da47cb943ea4d91995be2c5a1105074"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0c320eb4f849af847ac19d5d177cbd"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Apply an 80-20 split\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    texts, numeric_labels, test_size=0.2, random_state=42\n)\n\n# Output the results\nprint(\"Train texts:\", len(train_texts))\nprint(\"Test texts:\", len(test_texts))\nprint(\"Train labels:\", len(train_labels))\nprint(\"Test labels:\", len(test_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:13.760512Z","iopub.execute_input":"2025-01-12T16:45:13.760795Z","iopub.status.idle":"2025-01-12T16:45:13.770249Z","shell.execute_reply.started":"2025-01-12T16:45:13.760763Z","shell.execute_reply":"2025-01-12T16:45:13.769427Z"}},"outputs":[{"name":"stdout","text":"Train texts: 2192\nTest texts: 549\nTrain labels: 2192\nTest labels: 549\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\ntest_dataset  = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:13.773838Z","iopub.execute_input":"2025-01-12T16:45:13.774037Z","iopub.status.idle":"2025-01-12T16:45:14.303784Z","shell.execute_reply.started":"2025-01-12T16:45:13.774020Z","shell.execute_reply":"2025-01-12T16:45:14.303121Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def chunk_text(examples, chunk_size=512):\n    \"\"\"\n    Splits each example's text into chunks of up to `chunk_size` words,\n    and replicates the label for each chunk.\n    \"\"\"\n    new_texts = []\n    new_labels = []\n\n    # examples[\"text\"] is now a *list* of strings\n    # examples[\"label\"] is now a *list* of labels\n    for text, label in zip(examples[\"text\"], examples[\"label\"]):\n        words = text.split()\n        for i in range(0, len(words), chunk_size):\n            chunk = \" \".join(words[i : i + chunk_size])\n            new_texts.append(chunk)\n            new_labels.append(label)\n\n    return {\"text\": new_texts, \"label\": new_labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:14.304864Z","iopub.execute_input":"2025-01-12T16:45:14.305163Z","iopub.status.idle":"2025-01-12T16:45:14.309852Z","shell.execute_reply.started":"2025-01-12T16:45:14.305139Z","shell.execute_reply":"2025-01-12T16:45:14.308952Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Apply chunking to train and test sets\ntrain_dataset = train_dataset.map(chunk_text, batched=True)\ntest_dataset  = test_dataset.map(chunk_text,  batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:14.310740Z","iopub.execute_input":"2025-01-12T16:45:14.310978Z","iopub.status.idle":"2025-01-12T16:45:15.296186Z","shell.execute_reply.started":"2025-01-12T16:45:14.310947Z","shell.execute_reply":"2025-01-12T16:45:15.295515Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2192 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ead30342645477984c63bda194e2840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/549 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6accd1d2dcb1458a97b2c41d73a5a8e5"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",  # or \"longest\", or dynamic padding\n        max_length=512         # or 256, or 512 depending on your data\n    )\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\n\n\n# The Trainer expects the columns \"input_ids\", \"attention_mask\", and \"labels\"\ntrain_dataset = train_dataset.rename_column(\"label\", \"labels\")\ntest_dataset = test_dataset.rename_column(\"label\", \"labels\")\n\n# set the format for PyTorch\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:15.297003Z","iopub.execute_input":"2025-01-12T16:45:15.297323Z","iopub.status.idle":"2025-01-12T16:45:30.958314Z","shell.execute_reply.started":"2025-01-12T16:45:15.297291Z","shell.execute_reply":"2025-01-12T16:45:30.957587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8420 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64682466d72041619d7ee649093e9eae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87fd885487d146b994a9f0b8d3044938"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"!pip install evaluate\nimport numpy as np\nfrom evaluate import load\nmetric = load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:30.959254Z","iopub.execute_input":"2025-01-12T16:45:30.959604Z","iopub.status.idle":"2025-01-12T16:45:36.259757Z","shell.execute_reply.started":"2025-01-12T16:45:30.959573Z","shell.execute_reply":"2025-01-12T16:45:36.258839Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8efaa2998e4e74bbf95ae11ba35482"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"from transformers import EarlyStoppingCallback\ntraining_args = TrainingArguments(\n    output_dir=\"best_performing_TurkishBERTweet\",\n    eval_strategy=\"steps\",    # Evaluate at regular steps\n    eval_steps=50,                  # Evaluation frequency\n    save_strategy=\"steps\",\n    save_steps=50,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,\n    logging_steps=10,               # Log every 10 steps\n    logging_dir=\"./logs\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    save_total_limit=1,\n    disable_tqdm=False,             # Enable progress bars\n    report_to=[\"none\"]              # Disable integration reports\n)\n# Initialize the EarlyStoppingCallback\nearly_stopping = EarlyStoppingCallback(\n    early_stopping_patience=3,      # Stop after 2 evaluations with no improvement\n    early_stopping_threshold=0.0    # Minimum change to qualify as improvement\n)\n\n# Ensure all model parameters are contiguous\nfor param in model.parameters():\n    param.data = param.data.contiguous()\n\nfrom torch.optim import AdamW\n\n# Define weight decay parameters\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\n        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.01,  # Adjust weight decay as needed\n    },\n    {\n        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\n\n# Initialize the optimizer with the custom learning rate\noptimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n\nfrom transformers import get_linear_schedule_with_warmup\n\n# Calculate the total number of training steps\nnum_epochs = training_args.num_train_epochs\nnum_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * num_epochs\n\n# Define the number of warmup steps\nnum_warmup_steps = int(0.1 * num_training_steps)  # 10% of training steps for warmup\n\n# Initialize the scheduler\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:47:08.566908Z","iopub.execute_input":"2025-01-12T16:47:08.567297Z","iopub.status.idle":"2025-01-12T16:47:08.951669Z","shell.execute_reply.started":"2025-01-12T16:47:08.567267Z","shell.execute_reply":"2025-01-12T16:47:08.950764Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"print(model)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,       # Include validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, lr_scheduler),  # Pass the optimizer and scheduler here\n    callbacks=[early_stopping]      # Add the early stopping callback\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:47:16.028280Z","iopub.execute_input":"2025-01-12T16:47:16.028618Z","iopub.status.idle":"2025-01-12T17:18:17.307442Z","shell.execute_reply.started":"2025-01-12T16:47:16.028589Z","shell.execute_reply":"2025-01-12T17:18:17.306501Z"}},"outputs":[{"name":"stdout","text":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=10, bias=True)\n)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1650' max='10530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1650/10530 30:59 < 2:46:58, 0.89 it/s, Epoch 1/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.385200</td>\n      <td>2.380813</td>\n      <td>0.063779</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.338500</td>\n      <td>2.308991</td>\n      <td>0.080438</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.198100</td>\n      <td>2.208130</td>\n      <td>0.194193</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.065000</td>\n      <td>2.145902</td>\n      <td>0.201333</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>2.091600</td>\n      <td>2.092469</td>\n      <td>0.265112</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.069800</td>\n      <td>2.067296</td>\n      <td>0.273203</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>2.043400</td>\n      <td>2.039759</td>\n      <td>0.286054</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.042600</td>\n      <td>1.985015</td>\n      <td>0.322703</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.894900</td>\n      <td>1.889013</td>\n      <td>0.365540</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.796700</td>\n      <td>1.723411</td>\n      <td>0.468348</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.635400</td>\n      <td>1.543910</td>\n      <td>0.536411</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.281400</td>\n      <td>1.392313</td>\n      <td>0.617325</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.255100</td>\n      <td>1.285407</td>\n      <td>0.619705</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.159900</td>\n      <td>1.192592</td>\n      <td>0.637792</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.035800</td>\n      <td>1.106131</td>\n      <td>0.663018</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.083000</td>\n      <td>1.087730</td>\n      <td>0.684436</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.075600</td>\n      <td>1.076131</td>\n      <td>0.672537</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.126500</td>\n      <td>1.059961</td>\n      <td>0.680628</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.158300</td>\n      <td>1.009003</td>\n      <td>0.686340</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.843300</td>\n      <td>1.052827</td>\n      <td>0.674441</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.030000</td>\n      <td>0.998015</td>\n      <td>0.692527</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.699000</td>\n      <td>0.981322</td>\n      <td>0.699667</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.848000</td>\n      <td>0.992672</td>\n      <td>0.697287</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.772000</td>\n      <td>0.996128</td>\n      <td>0.699191</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.905900</td>\n      <td>0.970958</td>\n      <td>0.714422</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.607700</td>\n      <td>0.974963</td>\n      <td>0.711566</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.128300</td>\n      <td>0.932735</td>\n      <td>0.714898</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.043900</td>\n      <td>0.960308</td>\n      <td>0.701095</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.727700</td>\n      <td>0.950306</td>\n      <td>0.712042</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.787200</td>\n      <td>0.935445</td>\n      <td>0.717277</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.800100</td>\n      <td>0.938195</td>\n      <td>0.702999</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.641000</td>\n      <td>0.960837</td>\n      <td>0.698239</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.792100</td>\n      <td>0.953524</td>\n      <td>0.699191</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1650, training_loss=1.352440616723263, metrics={'train_runtime': 1860.1332, 'train_samples_per_second': 45.266, 'train_steps_per_second': 5.661, 'total_flos': 3472262876995584.0, 'train_loss': 1.352440616723263, 'epoch': 1.566951566951567})"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"predictions = trainer.predict(test_dataset)\nprint(predictions.metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:27:23.407569Z","iopub.execute_input":"2025-01-12T17:27:23.407923Z","iopub.status.idle":"2025-01-12T17:27:54.959199Z","shell.execute_reply.started":"2025-01-12T17:27:23.407892Z","shell.execute_reply":"2025-01-12T17:27:54.958320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'test_loss': 0.9354445338249207, 'test_accuracy': 0.7172774869109948, 'test_runtime': 31.542, 'test_samples_per_second': 66.61, 'test_steps_per_second': 8.338}\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nimport emoji\nfrom scipy.sparse import hstack\n\n\n# to keep the label order\ntest_usernames = []\ntest_captions = []\ntest_bio = []\n\nfor username, posts in username2posts_test.items():\n  test_usernames.append(username)\n  user_profile = username2profile_test.get(username, {})\n  user_biography = user_profile.get(\"biography\") or \"\"\n  user_biography = preprocess(user_biography) #using the preprocessor of the model\n  test_bio.append(user_biography)\n  # aggregating the posts per user\n  cleaned_captions = []\n  for post in posts:\n    post_caption = post.get(\"caption\", \"\")\n    if post_caption is None:\n      continue\n    post_caption = preprocess(post_caption)\n    if post_caption != \"\":\n      cleaned_captions.append(post_caption)\n  user_post_captions = \" \".join(cleaned_captions)\n  if not user_post_captions.strip():\n    print(\"User \" + username + \" from test has empty captions.\")\n\n  test_captions.append(user_post_captions)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:41:46.864839Z","iopub.execute_input":"2025-01-12T17:41:46.865173Z","iopub.status.idle":"2025-01-12T17:46:17.019002Z","shell.execute_reply.started":"2025-01-12T17:41:46.865149Z","shell.execute_reply":"2025-01-12T17:46:17.018256Z"}},"outputs":[{"name":"stdout","text":"User sanatdan_ from test has empty captions.\nUser modamizbir from test has empty captions.\nUser deeprockbar35 from test has empty captions.\nUser flamingo_fashionn from test has empty captions.\nUser dogukandrl from test has empty captions.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"test_texts = []\nfor bio_text, captions_text in zip(test_bio, test_captions):\n    combined_text = bio_text.strip() + \" \" + captions_text.strip()\n    test_texts.append(combined_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:46:52.183513Z","iopub.execute_input":"2025-01-12T17:46:52.183818Z","iopub.status.idle":"2025-01-12T17:46:52.246769Z","shell.execute_reply.started":"2025-01-12T17:46:52.183794Z","shell.execute_reply":"2025-01-12T17:46:52.245837Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"test_texts[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:46:58.994987Z","iopub.execute_input":"2025-01-12T17:46:58.995488Z","iopub.status.idle":"2025-01-12T17:46:59.002081Z","shell.execute_reply.started":"2025-01-12T17:46:58.995450Z","shell.execute_reply":"2025-01-12T17:46:59.001188Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'beyaz yakalıların dünyasına hoşgeldiniz <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> bu diyaloğun yaşanmadığı bir online toplantı olmaz olamaz <emoji> sevinç_gözyaşlarıyla_yüzleşmek </emoji> evet ocak ayında beyaz yakalı whatsup gruplarında en çok sorulan soru, <emoji> sırıtan_yüz </emoji> hayır post gecikmeli değil, hala öğrenememiş olan binlerce kişi olduğunu söyleyebilirim ama ispat edemem <emoji> kötülük_görmeyen_maymun </emoji> <emoji> sırıtan_yüz </emoji> yine yuzlercesini gorecegimiz maillerden biri <emoji> sırıtan_yüz </emoji> <emoji> kötülük_görmeyen_maymun </emoji> i̇yi haftalar ! <emoji> sırıtan_yüz </emoji> bir iç ses <emoji> sırıtan_yüz </emoji> 10 dk kahve içmek mi <emoji> sırıtan_yüz </emoji> <emoji> kötülük_görmeyen_maymun </emoji> geldi hesap kitap ayları <emoji> sırıtan_yüz </emoji> <emoji> kötülük_görmeyen_maymun </emoji> yaşayan bilir. sen, ben, hepimiz <emoji> kötülük_görmeyen_maymun </emoji> . . <hashtag> beyazyakalı </hashtag> <hashtag> beyazyaka </hashtag> <hashtag> beyazyakaliyiz </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> homeoffice </hashtag> yeni hafta yeni umutlar <emoji> kötülük_görmeyen_maymun </emoji> <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> beyazyaka </hashtag> yaz ayının başlaması ile beyaz yakalılarında güney hayali sezonu açılmıştır, her tatil dönüşü dinleyeceğimiz ah gitsek ne güzel olurdu be diyaloglarına hazır mıyız? <emoji> kötülük_görmeyen_maymun </emoji> . . . <hashtag> beyazyakalılar </hashtag> <hashtag> beyazyakalı </hashtag> <hashtag> beyazyakalıyız </hashtag> <hashtag> kurumsalhayat </hashtag> home office devam edenlerin özlediği bazı detaylar <emoji> sevinç_gözyaşlarıyla_yüzleşmek </emoji> <emoji> sırıtan_yüz </emoji> . . <hashtag> homeoffice </hashtag> <hashtag> officediaries </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakali </hashtag> <hashtag> beyazyaka </hashtag> <hashtag> beyazyakalilar </hashtag> toplantıda lafı ağza tıkılan, tam birşey anlatırken sözü müdürü tarafından kesilen, müşteri önünde tüm hataların sorumlusu ilan edildikten sonra yüzü düşen çalışanın gönlünü almaya çalışan tüm yöneticilere gelsin <emoji> yüz_ekşitme </emoji> <emoji> i̇ri_gözlü_sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> beyazyakacaps </hashtag> home office olayı bitip şirkete dönen yoldaşlar el kaldırsın <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> . . <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakalilar </hashtag> <hashtag> beyazyakaliolmak </hashtag> <hashtag> homeoffice </hashtag> <hashtag> kurumsalhayat </hashtag> merak ettiğim bir konu var, bu yasaklarda evde küçük çocuğu olan , kreşe gidemeyen, eve bakıcı/anane/babane gelemeyen durumlar için, hiç kolaylık sağlayan şirketler oldu mu? full pc başında olması beklenen ama aynı zamanda kendi tuvaletini yapamayan su içemeyen yemek yiyemeyen oyun oynayamayan çocuğuda bakması gereken bir ebeveyn. şu dönemde sağlanan kolaylıklar aidiyet duygusunu arttırır şirkete karşı ,ama henüz hiç duymadım çevreden , varmı sizin bildiğiniz böyle şirketler <emoji> kötülük_görmeyen_maymun </emoji> <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> tamkapanma </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> evdençalışmazorlukları </hashtag> <hashtag> homeoffice </hashtag> <hashtag> beyazyakalıolmak </hashtag> bir pazar akşamına yakışmayacak tek şey; pazartesi sabahına hazır olması beklenilen o sunumun hazır olmadığı gerçeğidir <emoji> woman_facepalming_açık_cilt_tonu </emoji> <emoji> yüz_ekşitme </emoji> allah yar ve yardımcım olsun <emoji> kötülük_görmeyen_maymun </emoji> . . . <hashtag> beyazyakalıolmak </hashtag> <hashtag> homeofficegünleri </hashtag> <hashtag> evdençalışmak </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> beyazyakalıyız </hashtag> sen,ben, hepimiz <emoji> sırıtan_yüz </emoji> <emoji> gülen_gözlerle_gülen_yüz </emoji> <emoji> omuz_silken_kadın_açık_ten_tonu </emoji> . . . <hashtag> beyazyaka </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> beyazyakaliyiz </hashtag> <hashtag> kurumsalhayat </hashtag> ama tabiki söyleyemedi ve yine yüzlerce gerekçe ile kendini parçaladı <emoji> omuz_silken_erkek_orta-açık_cilt_tonu </emoji> her pazartesi mesai öncesi toplantı yaparak dünyayı yeniden kurtaracağını sanan tüm müdürlere selam olsun, yarın sabah kim böyle olacak <emoji> sırıtan_yüz </emoji> <emoji> woman_facepalming_açık_cilt_tonu </emoji> <emoji> omuz_silken_erkek_orta-açık_cilt_tonu </emoji> sadece 5 dakika arada en fazla ne kadar şey isteyebilirler acaba merak ediyorum <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> arka fonu deniz olan yeni haftaya başladık fotolarını paylaşan beyaz yakalıları alınlarından öpmek , tebriklerimi iletmek istiyorum <emoji> sırıtan_yüz </emoji> bende yemiyor bu paylaşımlar, sizde durumlar nedir? <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> homeoffice </hashtag> <hashtag> homeofficegünlükleri </hashtag> <hashtag> beyazyakalı </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> ofisgeyikleri </hashtag> yine bir toplantıda, satış sektörde olanları, rakipleri anlatıyor,anlatıyor, anlatıyordu.. <emoji> sırıtan_yüz </emoji> <emoji> gülmek_yerde_yuvarlanmak </emoji> <emoji> kötülük_görmeyen_maymun </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> homeoffice </hashtag> <hashtag> zoommeeting </hashtag> <hashtag> sanalofis </hashtag> şirketlere dönüş başlasa da video call’lar uzunca bir süre sürecek gibi , ve bizde hiç yüz yüze görüşemediğimiz müşterileri bir heyecan ekranda görüp tanışmaya devam edeceğiz. sevgili arkadaşlar lütfen video call ismimizi , her toplantı öncesi kontrol edelim, zira koskoca gmy yada direktörü çocugunun kullanıcı adı ile görünce benim konsantrasyonum bozuluyor <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> homeoffice </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> homeofishalleri </hashtag> <hashtag> skype </hashtag> <hashtag> videocall </hashtag> home office’i pembe bir rüya olarak düşünenler ? hala aynı fikirde misiniz? <emoji> sırıtan_yüz </emoji> “ <emoji> başparmak_havaya </emoji> ” ve “ <emoji> başparmak_aşağı </emoji> ” olarak yorum bırakmadan geçmeyiniz <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıolmak </hashtag> <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> homeofficegünlükleri </hashtag> <hashtag> homeoffice </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> ofishalleri </hashtag> arkadaşlar video call görüşmelerinde mute tuşunu öğrenelim, öğretelim, elden ele yayalım. yoksa halimiz harap. saygılar <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> homeoffice </hashtag> <hashtag> homeofficeçalışmak </hashtag> <hashtag> videocallhataları </hashtag> evden çalışmayı,kahvesini yudumlayarak yapan varsa alnından öpesim var, yeminlen bezdim vallahi bezdim billahi bezdim, ne kadar yapılmayacak iş varsa, şimdi yerinde yeller esen 3 yıl önce ret olan projenin detayı varsa , video call lar eşliğinde yapıyoruz. hayır işteyken molaya çıkardık tuvalete giderdik göze batmazdı, şimdi evdesin ya bilgisayar başından 3 dk ayrılınca neredesin mesajı geliyor, bir ben miyim ? yalnız olmadığımı söyleyin rahatlayayım <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalı </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> homeoffice </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> ofishalleri </hashtag> o son 10 dk, kapanış cümleleri, karar çıkmayan toplantılar, ne içersinizler, bunu sen yap bunu o yapsınlar, <emoji> kötülük_görmeyen_maymun </emoji> . . . . <hashtag> beyazyakalı </hashtag> <hashtag> beyazyakalıyız </hashtag> <hashtag> plazacılık </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgün </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> beyazyakalılar </hashtag> terfi dönemi beyaz yakalılar <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalı </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgün </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> plazahayatı </hashtag> birde maaşı almadan önceki gün videosu koyayımda aradaki 7 büyük farkı bulalım <emoji> sırıtan_yüz </emoji> <emoji> sevinç_gözyaşlarıyla_yüzleşmek </emoji> . maaşı alma - maaşın bitmesi konulu videolarınızda beni etiketlemeyi unutmayın <emoji> sırıtan_yüz </emoji> . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> maaşgünü </hashtag> <hashtag> plazahayatı </hashtag> <hashtag> capsvideo </hashtag> <hashtag> adilenaşit </hashtag> yarın projesini sunacak tüm akadaşlara başarılar dilerznnznhahsmj <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> kötülük_görmeyen_maymun </emoji> <emoji> kötülük_görmeyen_maymun </emoji> <emoji> kötülük_görmeyen_maymun </emoji> <emoji> kötülük_görmeyen_maymun </emoji> <emoji> kötülük_görmeyen_maymun </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakalilar </hashtag> <hashtag> beyazyakali </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> kurumsalyasam </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> ofishalleri </hashtag> <emoji> bullseye </emoji> toplantı amacı: sorun çözmek,karar almak, süreç geliştirmek vs vs. . gerçekleşen: bırak bir karar almayı; var olan konuyu daha da kaosa sürükleyerek,kucağında 10 tane ekstra konu ile bir diğer toplantıda karar almak üzere odadan ayrılmak <emoji> kötülük_görmeyen_maymun </emoji> <emoji> kötülük_görmeyen_maymun </emoji> . gerçekten merak ediyorum, toplantılardan bir karar alıp çıkabilen şirketler var mı <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> toplantıgeyikleri </hashtag> <hashtag> plazacılık </hashtag> beyaz yakalıların kurumsal hayatta belli bir süre geçirip, okulda öğrendiklerini gösteremeden geçirdiği yılların isyanı ektedir <emoji> sırıtan_yüz </emoji> . . . nerede bu ceteris paribuslar , arz talep eğrileri,fifolar , lifolar , belirsiz integraller,matrisler? <emoji> sırıtan_yüz </emoji> <emoji> yüzü_kızarmış </emoji> <emoji> sevinç_gözyaşlarıyla_yüzleşmek </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> beyazyaka </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgün </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> evet yağmur çamur demeden pişileri gömdüysek yeni haftaya hazırız <emoji> sırıtan_yüz </emoji> . . . <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalı </hashtag> <hashtag> beyazyakalıolmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> veliaht şirkete gelmiştir , ilgi manyağı olmuştur! <emoji> sırıtan_şaşı_yüz </emoji> . . . . <hashtag> beyazyakalı </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> patronunoğlu </hashtag> <hashtag> beyazyakalılar </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> maslak </hashtag> kimlerin bakiyesi hala bitmedi <emoji> sırıtan_yüz </emoji> . . . <hashtag> kurumsalkimlik </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgün </hashtag> <hashtag> öğlearası </hashtag> <hashtag> beyazyakalı </hashtag> <hashtag> beyazyakalıyız </hashtag> <hashtag> beyazyakalıolmak </hashtag>'"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"test_data_path = \"/kaggle/input/cs412-dataset/test-classification-round3.dat\"\n\ntest_unames = []\nwith open(test_data_path, \"rt\") as fh:\n  for line in fh:\n    test_unames.append(line.strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:47:16.578614Z","iopub.execute_input":"2025-01-12T17:47:16.578900Z","iopub.status.idle":"2025-01-12T17:47:16.596822Z","shell.execute_reply.started":"2025-01-12T17:47:16.578879Z","shell.execute_reply":"2025-01-12T17:47:16.596022Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"test_unames[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:06:38.639954Z","iopub.execute_input":"2025-01-12T18:06:38.640258Z","iopub.status.idle":"2025-01-12T18:06:38.645302Z","shell.execute_reply.started":"2025-01-12T18:06:38.640235Z","shell.execute_reply":"2025-01-12T18:06:38.644477Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"['livapastanesi',\n 'barisgross',\n 'tusasshop',\n 'etolyadigital',\n 'tugrulonur',\n 'tulugozlu',\n 'gokidy',\n 'cengizgumus_official',\n 'krossbisiklet',\n 'haribochamallows']"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"test_data_text = []\nfor uname in test_unames:\n  try:\n    index = test_usernames.index(uname)\n    test_data_text.append(test_texts[index])\n  except Exception as e:\n    try:\n      index = train_usernames.index(uname)\n      test_data_text.append(texts[index])\n    except Exception as e:\n      print(uname)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:07:07.968751Z","iopub.execute_input":"2025-01-12T18:07:07.969056Z","iopub.status.idle":"2025-01-12T18:07:08.011038Z","shell.execute_reply.started":"2025-01-12T18:07:07.969034Z","shell.execute_reply":"2025-01-12T18:07:08.010126Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"len(test_data_text)\nlen(test_unames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:10:12.188705Z","iopub.execute_input":"2025-01-12T18:10:12.189011Z","iopub.status.idle":"2025-01-12T18:10:12.194193Z","shell.execute_reply.started":"2025-01-12T18:10:12.188987Z","shell.execute_reply":"2025-01-12T18:10:12.193279Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"from collections import defaultdict\nimport torch\n\n# Step 1: Create a Dataset for test data\nreal_test_dataset = Dataset.from_dict({\"text\": test_data_text, \"username\": test_unames})\ndef chunk_text_no_label(examples, chunk_size=512):\n    new_texts = []\n    new_usernames = []\n\n    for text, uname in zip(examples[\"text\"], examples[\"username\"]):\n        words = text.split()\n        for i in range(0, len(words), chunk_size):\n            chunk = \" \".join(words[i : i + chunk_size])\n            new_texts.append(chunk)\n            new_usernames.append(uname)\n\n    return {\"text\": new_texts, \"username\": new_usernames}\n    \nreal_test_dataset = real_test_dataset.map(\n    chunk_text_no_label, \n    batched=True, \n    remove_columns=real_test_dataset.column_names\n)\n\ndef tokenize_function(examples):\n    encodings = tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n    # Just return whatever the tokenizer gives plus the username\n    encodings[\"username\"] = examples[\"username\"]  \n    return encodings\n\nreal_test_dataset = real_test_dataset.map(tokenize_function, batched=True)\n\n# Store everything in a plain arrow/pandas structure\ndf_test = real_test_dataset.to_pandas()\n\nreal_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]\n)\n\n\n\n\n# Step 5: Run predictions\npredictions = trainer.predict(real_test_dataset)\n\nimport numpy as np\nimport torch\n\nlogits = predictions.predictions  # shape [n_chunks, n_classes]\nlogits_df = pd.DataFrame(logits, columns=list(range(logits.shape[1])))\ndf_test = real_test_dataset.to_pandas()\nlogits_df[\"username\"] = df_test[\"username\"].values\n# 3) Average per username\navg_logits = logits_df.groupby(\"username\").mean()  # shape: [n_users, n_classes]\n\n# 4) Identify highest logit column => idxmax\npred_class_per_user = avg_logits.idxmax(axis=1)  # this will give an integer column name\nuser2pred_class = pred_class_per_user.to_dict()\n\n'''pred_ids = np.argmax(logits, axis=-1)  # shape [n_chunks]\ndf_test[\"pred_id\"] = pred_ids\nuser2chunks = df_test.groupby(\"username\")[\"pred_id\"].agg(lambda x: x.value_counts().index[0])\n# Convert logits to a DataFrame\nlogits_df = pd.DataFrame(logits)\nlogits_df[\"username\"] = df_test[\"username\"].values\n\n# Now group by user and average the logits\navg_logits = logits_df.groupby(\"username\").mean()\n\n# For each user, pick the class with the highest average logit\npred_class_per_user = avg_logits.idxmax(axis=1)\n\n\nuser2pred_class = user2chunks.to_dict()\n'''\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:42:15.383490Z","iopub.execute_input":"2025-01-12T18:42:15.383821Z","iopub.status.idle":"2025-01-12T18:43:26.522134Z","shell.execute_reply.started":"2025-01-12T18:42:15.383795Z","shell.execute_reply":"2025-01-12T18:43:26.521268Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3705ccd35554c8ea06d40bf5105e653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4274 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ee6b77c2a143699f5ff0e744c34a86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"'pred_ids = np.argmax(logits, axis=-1)  # shape [n_chunks]\\ndf_test[\"pred_id\"] = pred_ids\\nuser2chunks = df_test.groupby(\"username\")[\"pred_id\"].agg(lambda x: x.value_counts().index[0])\\n# Convert logits to a DataFrame\\nlogits_df = pd.DataFrame(logits)\\nlogits_df[\"username\"] = df_test[\"username\"].values\\n\\n# Now group by user and average the logits\\navg_logits = logits_df.groupby(\"username\").mean()\\n\\n# For each user, pick the class with the highest average logit\\npred_class_per_user = avg_logits.idxmax(axis=1)\\n\\n\\nuser2pred_class = user2chunks.to_dict()\\n'"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"id2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:40:01.686395Z","iopub.execute_input":"2025-01-12T18:40:01.686688Z","iopub.status.idle":"2025-01-12T18:40:01.692083Z","shell.execute_reply.started":"2025-01-12T18:40:01.686664Z","shell.execute_reply":"2025-01-12T18:40:01.691173Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"{0: 'mom and children',\n 1: 'food',\n 2: 'travel',\n 3: 'gaming',\n 4: 'fashion',\n 5: 'health and lifestyle',\n 6: 'tech',\n 7: 'entertainment',\n 8: 'sports',\n 9: 'art'}"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"len(user2pred_class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:08.793442Z","iopub.execute_input":"2025-01-12T18:44:08.793831Z","iopub.status.idle":"2025-01-12T18:44:08.799884Z","shell.execute_reply.started":"2025-01-12T18:44:08.793795Z","shell.execute_reply":"2025-01-12T18:44:08.798984Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"import json\nmapped_dict = {key: id2label[value] for key, value in user2pred_class.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:13.344637Z","iopub.execute_input":"2025-01-12T18:44:13.344939Z","iopub.status.idle":"2025-01-12T18:44:13.349045Z","shell.execute_reply.started":"2025-01-12T18:44:13.344917Z","shell.execute_reply":"2025-01-12T18:44:13.348192Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"bert_results_df = pd.DataFrame(list(mapped_dict.items()), columns=['username', 'predicted_class'])\nbert_results_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:17.064730Z","iopub.execute_input":"2025-01-12T18:44:17.065140Z","iopub.status.idle":"2025-01-12T18:44:17.074302Z","shell.execute_reply.started":"2025-01-12T18:44:17.065082Z","shell.execute_reply":"2025-01-12T18:44:17.073314Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"            username predicted_class\n0         01burdaavm            food\n1          1001sanat             art\n2        1983beyoglu            food\n3        253binyasin   entertainment\n4  35likmeyhaneizmir            food","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>predicted_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01burdaavm</td>\n      <td>food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001sanat</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1983beyoglu</td>\n      <td>food</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>253binyasin</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35likmeyhaneizmir</td>\n      <td>food</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"count = 0\nfor username in username2posts_train:\n  if username in test_unames:\n    count += 1\nprint(f\"There are {count} overlapping instances in the training dataset and 1000 classification test instances\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:20.196623Z","iopub.execute_input":"2025-01-12T18:44:20.196913Z","iopub.status.idle":"2025-01-12T18:44:20.234141Z","shell.execute_reply.started":"2025-01-12T18:44:20.196890Z","shell.execute_reply":"2025-01-12T18:44:20.233340Z"}},"outputs":[{"name":"stdout","text":"There are 266 overlapping instances in the training dataset and 1000 classification test instances\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"# Iterate over rows in the dataframe\noverlapping_count = 0\ncorrect_prediction = 0\nwrong_prediction = 0\nfor index, row in bert_results_df.iterrows():\n    username = row['username']\n    predicted_class = row['predicted_class']\n    if username in username2_category:\n        actual_class = username2_category.get(username)\n        overlapping_count += 1\n        if predicted_class == actual_class:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is true\")\n            correct_prediction += 1\n        else:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is NOT true. True label is {actual_class}\")\n            bert_results_df.at[index, 'predicted_class'] = actual_class\n            wrong_prediction += 1\n\nprint(f\"There are {overlapping_count} overlapping instances in the training dataset and 1000 classification test instances\\n\")\nprint(f\"{correct_prediction} are correctly classified, {wrong_prediction} are incorrectly classified.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:27.787390Z","iopub.execute_input":"2025-01-12T18:44:27.787692Z","iopub.status.idle":"2025-01-12T18:44:27.881152Z","shell.execute_reply.started":"2025-01-12T18:44:27.787667Z","shell.execute_reply":"2025-01-12T18:44:27.878633Z"}},"outputs":[{"name":"stdout","text":"The user 1001sanat is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user _helinkandemir is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user acarflowers is in the training data, and the prediction art is true\nThe user adnanturankb is in the training data, and the prediction health and lifestyle is true\nThe user agoraavm_antalya is in the training data, and the prediction entertainment is true\nThe user ahmetmaranki is in the training data, and the prediction food is NOT true. True label is health and lifestyle\nThe user akcoat_official is in the training data, and the prediction tech is true\nThe user akhisarpresshaber is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user alfaglb is in the training data, and the prediction food is true\nThe user alialtuntasbaskan is in the training data, and the prediction health and lifestyle is true\nThe user alicanaytekin is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user alldaycharm is in the training data, and the prediction fashion is true\nThe user altekyapi is in the training data, and the prediction tech is true\nThe user altinorumcek is in the training data, and the prediction tech is true\nThe user ankaranobeltipkitabevleri is in the training data, and the prediction health and lifestyle is NOT true. True label is art\nThe user applegurgencler is in the training data, and the prediction tech is true\nThe user araskarafil is in the training data, and the prediction entertainment is true\nThe user ardahalil is in the training data, and the prediction health and lifestyle is true\nThe user argonotlar.sanat is in the training data, and the prediction art is true\nThe user asiyansanat is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user aslanegegrup is in the training data, and the prediction tech is true\nThe user ataberk.dogan is in the training data, and the prediction entertainment is NOT true. True label is gaming\nThe user ataguroffice is in the training data, and the prediction tech is NOT true. True label is fashion\nThe user atalaraleyna is in the training data, and the prediction fashion is true\nThe user avbakidemirbas is in the training data, and the prediction health and lifestyle is true\nThe user bahar_eli is in the training data, and the prediction art is true\nThe user baharakinci is in the training data, and the prediction travel is true\nThe user barbarosfarm is in the training data, and the prediction food is true\nThe user barisgross is in the training data, and the prediction food is true\nThe user bebebiyat is in the training data, and the prediction art is true\nThe user bekiraltantr is in the training data, and the prediction health and lifestyle is true\nThe user beko_serdar is in the training data, and the prediction tech is true\nThe user benismailyildirimm is in the training data, and the prediction mom and children is NOT true. True label is entertainment\nThe user berkaytulumbaci is in the training data, and the prediction art is true\nThe user besiktasshipyard is in the training data, and the prediction travel is NOT true. True label is tech\nThe user beykozkultursanat is in the training data, and the prediction entertainment is NOT true. True label is art\nThe user beymenclub is in the training data, and the prediction fashion is true\nThe user bihterkocc is in the training data, and the prediction fashion is true\nThe user bingolbel is in the training data, and the prediction health and lifestyle is true\nThe user bomotorsport is in the training data, and the prediction sports is true\nThe user borckabld is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user brixtonturkiye is in the training data, and the prediction tech is NOT true. True label is travel\nThe user bskcemildeveci is in the training data, and the prediction health and lifestyle is true\nThe user buckheadturkey is in the training data, and the prediction fashion is true\nThe user bullentoz is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user burkaystagram is in the training data, and the prediction entertainment is true\nThe user bursayasam is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user call_me_mumsy is in the training data, and the prediction fashion is NOT true. True label is health and lifestyle\nThe user canyucetas is in the training data, and the prediction entertainment is true\nThe user carpetartofficial is in the training data, and the prediction art is true\nThe user cengizgumus_official is in the training data, and the prediction fashion is true\nThe user cengizsemercio is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user cevaheer is in the training data, and the prediction fashion is true\nThe user cibalikapibalikcisi is in the training data, and the prediction food is true\nThe user coskunaltun36 is in the training data, and the prediction health and lifestyle is NOT true. True label is travel\nThe user demiirhaan is in the training data, and the prediction fashion is NOT true. True label is health and lifestyle\nThe user dengemerkezi is in the training data, and the prediction health and lifestyle is true\nThe user denizliotizmdernegi is in the training data, and the prediction health and lifestyle is true\nThe user dentisteturkiye is in the training data, and the prediction health and lifestyle is true\nThe user desimerkez is in the training data, and the prediction tech is true\nThe user devrimyakut is in the training data, and the prediction art is true\nThe user didembalikofficial is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user didemeryarunlu is in the training data, and the prediction health and lifestyle is true\nThe user dijitalsosyalmedyam is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user dinersclubtr is in the training data, and the prediction travel is true\nThe user divan_sarraf is in the training data, and the prediction fashion is true\nThe user diyetisyengamzealtinay is in the training data, and the prediction health and lifestyle is true\nThe user dogakoyucatalca is in the training data, and the prediction food is true\nThe user donercibekirzade is in the training data, and the prediction food is true\nThe user drhalilibrahimtekin is in the training data, and the prediction health and lifestyle is true\nThe user durumle is in the training data, and the prediction food is true\nThe user duzceguvencomtr is in the training data, and the prediction travel is true\nThe user dyt.psk.bilgesakli is in the training data, and the prediction health and lifestyle is NOT true. True label is food\nThe user ebcinege is in the training data, and the prediction travel is true\nThe user eczozgurozel is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user edakok59 is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user eformspormerkezi is in the training data, and the prediction sports is true\nThe user eklerciumit is in the training data, and the prediction food is true\nThe user ekremcoskundoner is in the training data, and the prediction food is true\nThe user erdogantok55 is in the training data, and the prediction health and lifestyle is NOT true. True label is sports\nThe user esseklinik is in the training data, and the prediction health and lifestyle is true\nThe user estehair is in the training data, and the prediction health and lifestyle is true\nThe user eurovisn_turkey is in the training data, and the prediction entertainment is true\nThe user farukerdem is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user fatmasamsayilmaz is in the training data, and the prediction travel is true\nThe user fiatkastamonugozde is in the training data, and the prediction tech is true\nThe user fizikseltiyatro is in the training data, and the prediction art is true\nThe user flotalofficial is in the training data, and the prediction fashion is NOT true. True label is tech\nThe user fourestcalticak is in the training data, and the prediction travel is true\nThe user fundafashion is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user galenikecza is in the training data, and the prediction health and lifestyle is true\nThe user galipensarioglu is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user gastronometro is in the training data, and the prediction food is true\nThe user gazihastanesi is in the training data, and the prediction health and lifestyle is true\nThe user gelinevi_tv is in the training data, and the prediction entertainment is true\nThe user gezsenbatman is in the training data, and the prediction travel is NOT true. True label is food\nThe user gokcinarnecdet is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user gokgunnec is in the training data, and the prediction health and lifestyle is true\nThe user gokhanozoguz is in the training data, and the prediction entertainment is true\nThe user gokidy is in the training data, and the prediction mom and children is true\nThe user gsb_hatay is in the training data, and the prediction sports is true\nThe user gulrizandic is in the training data, and the prediction health and lifestyle is true\nThe user gurhanaltundasar is in the training data, and the prediction entertainment is NOT true. True label is art\nThe user guronimobilya is in the training data, and the prediction fashion is NOT true. True label is art\nThe user gustogiyim is in the training data, and the prediction fashion is true\nThe user guzellik_hemsiresi is in the training data, and the prediction health and lifestyle is true\nThe user gzonemag is in the training data, and the prediction entertainment is true\nThe user hacettepe_university is in the training data, and the prediction health and lifestyle is NOT true. True label is tech\nThe user hasvetmedikal is in the training data, and the prediction health and lifestyle is NOT true. True label is tech\nThe user hayalevent is in the training data, and the prediction mom and children is NOT true. True label is fashion\nThe user hotech_ecosystem is in the training data, and the prediction tech is true\nThe user iamemrecaliskan is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user iamsiddeshjadhav is in the training data, and the prediction entertainment is NOT true. True label is art\nThe user ih_korkmaz is in the training data, and the prediction travel is NOT true. True label is health and lifestyle\nThe user ihealthsaglik is in the training data, and the prediction health and lifestyle is true\nThe user ikbalkaya is in the training data, and the prediction health and lifestyle is true\nThe user ikizlerbebefethiye is in the training data, and the prediction mom and children is true\nThe user iloveanalogue is in the training data, and the prediction art is true\nThe user indirimlix is in the training data, and the prediction food is NOT true. True label is entertainment\nThe user ipekozagan is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user isikcelik.a.s is in the training data, and the prediction tech is true\nThe user ismailgeduz is in the training data, and the prediction health and lifestyle is true\nThe user itsumijapon is in the training data, and the prediction food is true\nThe user izmiretkinlikhaberleri is in the training data, and the prediction travel is true\nThe user jumbokunefetr is in the training data, and the prediction food is true\nThe user kaan.sekban is in the training data, and the prediction entertainment is true\nThe user kandilliborsarestaurant is in the training data, and the prediction food is true\nThe user kerimsabanci is in the training data, and the prediction entertainment is true\nThe user kiralarsin is in the training data, and the prediction tech is true\nThe user kosbsocial is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user kozantepkunefe is in the training data, and the prediction food is true\nThe user kronospan is in the training data, and the prediction art is true\nThe user limak.hotels is in the training data, and the prediction travel is true\nThe user liqui_moly_turkey is in the training data, and the prediction tech is true\nThe user lisebjkcom is in the training data, and the prediction sports is true\nThe user livingroomist is in the training data, and the prediction art is true\nThe user lokmanhekimhastaneleri is in the training data, and the prediction health and lifestyle is true\nThe user longosphere is in the training data, and the prediction travel is NOT true. True label is health and lifestyle\nThe user luleburgazbld is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user lutfusavas is in the training data, and the prediction health and lifestyle is true\nThe user m0rtyrick is in the training data, and the prediction entertainment is true\nThe user maestro.sanat.kursu is in the training data, and the prediction art is true\nThe user mandolinyayinlari is in the training data, and the prediction art is true\nThe user mcengizbozkurt is in the training data, and the prediction entertainment is true\nThe user medicasimple is in the training data, and the prediction tech is true\nThe user meltem.kursunlu is in the training data, and the prediction health and lifestyle is true\nThe user mentos_tr is in the training data, and the prediction food is true\nThe user mervekutlu is in the training data, and the prediction fashion is true\nThe user mgulluoglu is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user middelrestaurant is in the training data, and the prediction food is true\nThe user miniaturkmuzesi is in the training data, and the prediction art is true\nThe user minikseyler_ is in the training data, and the prediction mom and children is true\nThe user minimokirtasiye is in the training data, and the prediction art is true\nThe user mo_istanbul is in the training data, and the prediction travel is NOT true. True label is entertainment\nThe user moc_coffeeofficial is in the training data, and the prediction food is true\nThe user moisahne is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user mstismakinalari is in the training data, and the prediction tech is true\nThe user muratacilimranli is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user mutfakta_bebek_var is in the training data, and the prediction health and lifestyle is NOT true. True label is mom and children\nThe user muyashop is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user muzegazhane is in the training data, and the prediction art is true\nThe user mxnsturkey is in the training data, and the prediction food is true\nThe user nanopax_com is in the training data, and the prediction tech is true\nThe user nedimkaplann is in the training data, and the prediction health and lifestyle is true\nThe user nergiscorakci is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user netafimturkiye is in the training data, and the prediction tech is true\nThe user ntaslicay is in the training data, and the prediction health and lifestyle is true\nThe user onurkuyumcu1919 is in the training data, and the prediction fashion is true\nThe user opdrerdemzengin is in the training data, and the prediction health and lifestyle is true\nThe user ozakgokturk is in the training data, and the prediction travel is true\nThe user ozgeyagizz is in the training data, and the prediction fashion is NOT true. True label is entertainment\nThe user palomamarina_suites is in the training data, and the prediction travel is true\nThe user pasinlerbld is in the training data, and the prediction health and lifestyle is true\nThe user patara.well is in the training data, and the prediction health and lifestyle is true\nThe user pendikbelediyesi is in the training data, and the prediction sports is NOT true. True label is travel\nThe user petopytr is in the training data, and the prediction health and lifestyle is true\nThe user pilatesannesi is in the training data, and the prediction health and lifestyle is true\nThe user pillavidenizli is in the training data, and the prediction food is true\nThe user pluscomiletisim is in the training data, and the prediction food is NOT true. True label is tech\nThe user polarisayakkabi is in the training data, and the prediction fashion is true\nThe user poyrazotomotiv is in the training data, and the prediction tech is true\nThe user primepuritypep is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user quartzclinique is in the training data, and the prediction health and lifestyle is true\nThe user rahmi.gencer is in the training data, and the prediction health and lifestyle is true\nThe user reiskuyumculuk is in the training data, and the prediction food is NOT true. True label is fashion\nThe user relaxmodeofficial is in the training data, and the prediction fashion is true\nThe user rengarenkkanal is in the training data, and the prediction travel is NOT true. True label is entertainment\nThe user richmondnua is in the training data, and the prediction health and lifestyle is true\nThe user rocscoffee is in the training data, and the prediction food is true\nThe user roketsan is in the training data, and the prediction tech is true\nThe user rotarttasarim is in the training data, and the prediction tech is true\nThe user rubisaglik is in the training data, and the prediction health and lifestyle is true\nThe user sabanozubelediyesi is in the training data, and the prediction entertainment is true\nThe user sacimsacinolsun is in the training data, and the prediction health and lifestyle is true\nThe user sadberkhanimmuzesi is in the training data, and the prediction art is true\nThe user safamecomercial is in the training data, and the prediction fashion is NOT true. True label is tech\nThe user sait.restaurant is in the training data, and the prediction food is true\nThe user scaniatr is in the training data, and the prediction tech is true\nThe user selamiersoyy is in the training data, and the prediction fashion is NOT true. True label is art\nThe user selcuklubel is in the training data, and the prediction health and lifestyle is true\nThe user selcuklukongremerkezi is in the training data, and the prediction entertainment is true\nThe user semihasahin is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user sena.sener is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user sendeyapsana is in the training data, and the prediction food is NOT true. True label is entertainment\nThe user serangocer is in the training data, and the prediction health and lifestyle is true\nThe user seturdutyfree is in the training data, and the prediction fashion is NOT true. True label is travel\nThe user sevketcoruh is in the training data, and the prediction entertainment is true\nThe user sinanguler is in the training data, and the prediction sports is true\nThe user sivilsayfalar is in the training data, and the prediction health and lifestyle is true\nThe user sky_uk is in the training data, and the prediction entertainment is true\nThe user socialbrandstr is in the training data, and the prediction tech is true\nThe user sonerarica1 is in the training data, and the prediction entertainment is true\nThe user sozerinsaatorhangazi is in the training data, and the prediction art is NOT true. True label is tech\nThe user spitalispecialbahceci is in the training data, and the prediction health and lifestyle is true\nThe user sporsuncom is in the training data, and the prediction sports is true\nThe user staynewinn is in the training data, and the prediction travel is true\nThe user steakhousegunaydin is in the training data, and the prediction food is true\nThe user stonebarizmir is in the training data, and the prediction food is true\nThe user studio.oyunculari is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user suleymansarilar is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user sumerpark_avm is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user superfitshoes_turkey is in the training data, and the prediction fashion is NOT true. True label is health and lifestyle\nThe user swothospitality is in the training data, and the prediction travel is NOT true. True label is entertainment\nThe user takviyegiller is in the training data, and the prediction health and lifestyle is true\nThe user talyatasarimtr is in the training data, and the prediction tech is NOT true. True label is art\nThe user tarimoz is in the training data, and the prediction tech is true\nThe user tasarimgroup is in the training data, and the prediction art is true\nThe user tasovabelediyesi is in the training data, and the prediction health and lifestyle is true\nThe user tavukdunyasikariyer is in the training data, and the prediction food is true\nThe user telesuresigorta is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user tepebasibeltr is in the training data, and the prediction entertainment is true\nThe user theurbangoat.ist is in the training data, and the prediction food is true\nThe user tiyatrokast is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user tiyatroumay is in the training data, and the prediction art is true\nThe user tohumgubre is in the training data, and the prediction tech is true\nThe user tolgasaritas is in the training data, and the prediction entertainment is true\nThe user tonyhawk is in the training data, and the prediction sports is true\nThe user trendylarahotel is in the training data, and the prediction travel is true\nThe user trendysidebeach is in the training data, and the prediction travel is true\nThe user trumpavm is in the training data, and the prediction mom and children is NOT true. True label is health and lifestyle\nThe user tugcedural is in the training data, and the prediction entertainment is true\nThe user tugrulkuyumculuk is in the training data, and the prediction fashion is true\nThe user tugrulonur is in the training data, and the prediction sports is NOT true. True label is entertainment\nThe user turkerkilic is in the training data, and the prediction health and lifestyle is true\nThe user turkervip is in the training data, and the prediction travel is true\nThe user turkiyesualtisporlari is in the training data, and the prediction sports is true\nThe user turktraktorkariyer is in the training data, and the prediction tech is true\nThe user ugurakkafa is in the training data, and the prediction health and lifestyle is true\nThe user ugursengulx is in the training data, and the prediction health and lifestyle is true\nThe user umraniyebeltr is in the training data, and the prediction health and lifestyle is true\nThe user unolezzetleri is in the training data, and the prediction food is true\nThe user uras.benlioglu is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user ustapidecitr is in the training data, and the prediction food is true\nThe user utkucubukcuoglu is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user uykudunyasicom is in the training data, and the prediction health and lifestyle is true\nThe user vimerang is in the training data, and the prediction tech is true\nThe user viptrend.com.tr is in the training data, and the prediction fashion is NOT true. True label is tech\nThe user viteltr is in the training data, and the prediction tech is true\nThe user vmilor is in the training data, and the prediction food is true\nThe user weareomgteam is in the training data, and the prediction tech is true\nThe user yachtmurat is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user yamalioglumucevherat is in the training data, and the prediction fashion is true\nThe user yenicekoyu43 is in the training data, and the prediction travel is true\nThe user yigitcaliskan_ is in the training data, and the prediction entertainment is true\nThe user yoldabiblog is in the training data, and the prediction travel is true\nThe user zadevital is in the training data, and the prediction health and lifestyle is NOT true. True label is food\nThere are 266 overlapping instances in the training dataset and 1000 classification test instances\n\n186 are correctly classified, 80 are incorrectly classified.\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"mapped_df = pd.DataFrame(list(mapped_dict.items()), columns=[\"Key\", \"Category\"])\n\n# Create a dictionary from the DataFrame\nmapped_df = mapped_df.set_index('Key')['Category'].to_dict()\n# Get distinct values from the dictionary\ndistinct_values = list(set(mapped_df.values()))\ndistinct_values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Iterate over rows in the dataframe\noverlapping_count = 0\ncorrect_prediction = 0\nwrong_prediction = 0\nfor index, row in mapped_df.iterrows():\n    username = row['Key']\n    predicted_class = row['Value']\n    if username in username2_category:\n        actual_class = username2_category.get(username)\n        overlapping_count += 1\n        if predicted_class == actual_class:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is true\")\n            correct_prediction += 1\n        else:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is NOT true. True label is {actual_class}\")\n            predictions_df.at[index, 'predicted_class'] = actual_class\n            wrong_prediction += 1\n\nprint(f\"There are {overlapping_count} overlapping instances in the training dataset and 1000 classification test instances\\n\")\nprint(f\"{correct_prediction} are correctly classified, {wrong_prediction} are incorrectly classified.\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ntrain_classification_df = pd.read_csv(\"/kaggle/input/cs412-dataset/train-classification.csv\")\n# Rename the columns\ntrain_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n\n# Get the list of distinct category labels\ndistinct_categories = train_classification_df['category'].unique().tolist()\ndistinct_categories\ndistinct_categories.remove(\"Health and lifestyle\")\ndistinct_categories\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:24:50.057084Z","iopub.execute_input":"2025-01-12T18:24:50.057477Z","iopub.status.idle":"2025-01-12T18:24:50.082029Z","shell.execute_reply.started":"2025-01-12T18:24:50.057434Z","shell.execute_reply":"2025-01-12T18:24:50.081045Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"['Mom and Children',\n 'Food',\n 'Travel',\n 'Gaming',\n 'Fashion',\n 'Health and Lifestyle',\n 'Tech',\n 'Entertainment',\n 'Sports',\n 'Art']"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"# Mapping values from distinct_values to distinct_categories\nmapping = {}\nfor value in distinct_values:\n    for category in distinct_categories:\n        # Case-insensitive match\n        if value.lower() == category.lower():\n            mapping[value] = category\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:27:12.293530Z","iopub.execute_input":"2025-01-12T18:27:12.293837Z","iopub.status.idle":"2025-01-12T18:27:12.297824Z","shell.execute_reply.started":"2025-01-12T18:27:12.293811Z","shell.execute_reply":"2025-01-12T18:27:12.297123Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:27:16.919554Z","iopub.execute_input":"2025-01-12T18:27:16.919862Z","iopub.status.idle":"2025-01-12T18:27:16.925172Z","shell.execute_reply.started":"2025-01-12T18:27:16.919838Z","shell.execute_reply":"2025-01-12T18:27:16.924360Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"{'health and lifestyle': 'Health and Lifestyle',\n 'tech': 'Tech',\n 'entertainment': 'Entertainment',\n 'travel': 'Travel',\n 'sports': 'Sports',\n 'art': 'Art',\n 'food': 'Food',\n 'mom and children': 'Mom and Children',\n 'fashion': 'Fashion'}"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"updated_mapped_df = {\n    key: mapping.get(value, value) for key, value in mapped_df.items()\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:27:38.896614Z","iopub.execute_input":"2025-01-12T18:27:38.896897Z","iopub.status.idle":"2025-01-12T18:27:38.901359Z","shell.execute_reply.started":"2025-01-12T18:27:38.896875Z","shell.execute_reply":"2025-01-12T18:27:38.900393Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"len(updated_mapped_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:29:30.917623Z","iopub.execute_input":"2025-01-12T18:29:30.917940Z","iopub.status.idle":"2025-01-12T18:29:30.922728Z","shell.execute_reply.started":"2025-01-12T18:29:30.917917Z","shell.execute_reply":"2025-01-12T18:29:30.922027Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the output file path\noutput_file = \"prediction-classification-round3.json\"\n\n# Write the dictionary to a JSON file\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(updated_predictions_dict, f, indent=4, ensure_ascii=False)\n\nprint(f\"Predictions have been written to {output_file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 6: Aggregate predictions by username\nusername_predictions = defaultdict(list)\nfor example, predicted_class in zip(test_dataset, predicted_classes):\n    username_predictions[example[\"username\"]].append(predicted_class)\n\n# Step 7: Assign final prediction per username (e.g., majority voting)\nfinal_predictions = {}\nfor username, preds in username_predictions.items():\n    # Use majority vote for final prediction\n    final_predictions[username] = max(set(preds), key=preds.count)\n\n# final_predictions now contains the mapping of username -> predicted class","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}