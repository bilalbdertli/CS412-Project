{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10443025,"sourceType":"datasetVersion","datasetId":6463810},{"sourceId":10449169,"sourceType":"datasetVersion","datasetId":6467892},{"sourceId":10451357,"sourceType":"datasetVersion","datasetId":6469505}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ViralLab/TurkishBERTweet.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:10.610517Z","iopub.execute_input":"2025-01-12T16:40:10.610802Z","iopub.status.idle":"2025-01-12T16:40:11.781273Z","shell.execute_reply.started":"2025-01-12T16:40:10.610779Z","shell.execute_reply":"2025-01-12T16:40:11.780279Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'TurkishBERTweet'...\nremote: Enumerating objects: 1259, done.\u001b[K\nremote: Counting objects: 100% (759/759), done.\u001b[K\nremote: Compressing objects: 100% (469/469), done.\u001b[K\nremote: Total 1259 (delta 423), reused 621 (delta 290), pack-reused 500 (from 1)\u001b[K\nReceiving objects: 100% (1259/1259), 5.06 MiB | 31.00 MiB/s, done.\nResolving deltas: 100% (648/648), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install peft \n!pip install transformers\n!pip install urlextract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:11.782626Z","iopub.execute_input":"2025-01-12T16:40:11.782952Z","iopub.status.idle":"2025-01-12T16:40:27.075651Z","shell.execute_reply.started":"2025-01-12T16:40:11.782924Z","shell.execute_reply":"2025-01-12T16:40:27.074546Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\nCollecting huggingface-hub>=0.25.0 (from peft)\n  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, peft\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\nSuccessfully installed huggingface-hub-0.27.1 peft-0.14.0\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nCollecting urlextract\n  Downloading urlextract-1.9.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.10)\nCollecting uritools (from urlextract)\n  Downloading uritools-4.0.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from urlextract) (4.3.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.16.1)\nDownloading urlextract-1.9.0-py3-none-any.whl (21 kB)\nDownloading uritools-4.0.3-py3-none-any.whl (10 kB)\nInstalling collected packages: uritools, urlextract\nSuccessfully installed uritools-4.0.3 urlextract-1.9.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys\nsys.path.append('./TurkishBERTweet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:27.077730Z","iopub.execute_input":"2025-01-12T16:40:27.078033Z","iopub.status.idle":"2025-01-12T16:40:27.081642Z","shell.execute_reply.started":"2025-01-12T16:40:27.078011Z","shell.execute_reply":"2025-01-12T16:40:27.080826Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from Preprocessor import preprocess\n\ntext = \"\"\"Lab'Ä±mÄ±za \"viral\" adÄ±nÄ± verdik Ã§Ã¼nkÃ¼ amacÄ±mÄ±z disiplinler arasÄ± sÄ±nÄ±rlarÄ± aÅŸmak ve aralarÄ±nda yeni baÄŸlantÄ±lar kurmak! ğŸ”¬ #ViralLab\nhttps://varollab.com/\"\"\"\n\npreprocessed_text = preprocess(text)\nprint(preprocessed_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:27.082772Z","iopub.execute_input":"2025-01-12T16:40:27.083039Z","iopub.status.idle":"2025-01-12T16:40:27.183824Z","shell.execute_reply.started":"2025-01-12T16:40:27.083010Z","shell.execute_reply":"2025-01-12T16:40:27.183174Z"}},"outputs":[{"name":"stdout","text":"lab'Ä±mÄ±za \"viral\" adÄ±nÄ± verdik Ã§Ã¼nkÃ¼ amacÄ±mÄ±z disiplinler arasÄ± sÄ±nÄ±rlarÄ± aÅŸmak ve aralarÄ±nda yeni baÄŸlantÄ±lar kurmak! <emoji> mikroskop </emoji> <hashtag> virallab </hashtag> <http> varollab.com </http>\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom Preprocessor import preprocess\n\ntokenizer = AutoTokenizer.from_pretrained(\"VRLLab/TurkishBERTweet\")\nturkishBERTweet = AutoModelForSequenceClassification.from_pretrained(\"VRLLab/TurkishBERTweet\", num_labels=10)\n\ntext = \"\"\"Lab'Ä±mÄ±za \"viral\" adÄ±nÄ± verdik Ã§Ã¼nkÃ¼ amacÄ±mÄ±z disiplinler arasÄ± sÄ±nÄ±rlarÄ± aÅŸmak ve aralarÄ±nda yeni baÄŸlantÄ±lar kurmak! ğŸ’¥ğŸ”¬ #ViralLab #DisiplinlerArasÄ± #YenilikÃ§iBaÄŸlantÄ±lar\"\"\"\n\npreprocessed_text = preprocess(text)\ninput_ids = torch.tensor([tokenizer.encode(preprocessed_text)])\n\nwith torch.no_grad():\n    features = turkishBERTweet(input_ids)  # Models outputs are now tuples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:27.184640Z","iopub.execute_input":"2025-01-12T16:40:27.184920Z","iopub.status.idle":"2025-01-12T16:40:38.550444Z","shell.execute_reply.started":"2025-01-12T16:40:27.184888Z","shell.execute_reply":"2025-01-12T16:40:38.549704Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5f48d7679b4008949249fe7d6004c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.88M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21878bad5ecb474fb6d56521aa01a355"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.19M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1bde6a6ec6743028adbfc4cb3c6d4f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d491b24823149a39bf3298252fdd027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7aaf243fd174fb6b82e7e046606e3a4"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1aeffd745f4816937768a56e04e7b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/652M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28684855ccae4f79865c175e4aca4cc3"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at VRLLab/TurkishBERTweet and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Data Preprocessing and Cleaning","metadata":{}},{"cell_type":"code","source":"!pip install nltk\nimport numpy as np\nimport pandas as pd\nimport gzip\nimport json\n\nfrom pprint import pprint\n#@title Turkish StopWords\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('punkt_tab')\nturkish_stopwords = stopwords.words('turkish')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:38.551329Z","iopub.execute_input":"2025-01-12T16:40:38.551682Z","iopub.status.idle":"2025-01-12T16:40:43.399568Z","shell.execute_reply.started":"2025-01-12T16:40:38.551660Z","shell.execute_reply":"2025-01-12T16:40:43.398767Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.16.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_classification_df = pd.read_csv(\"/kaggle/input/cs412-dataset/train-classification.csv\")\ntrain_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n\n# Unifying labels\ntrain_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\nusername2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:43.400378Z","iopub.execute_input":"2025-01-12T16:40:43.400857Z","iopub.status.idle":"2025-01-12T16:40:43.432652Z","shell.execute_reply.started":"2025-01-12T16:40:43.400833Z","shell.execute_reply":"2025-01-12T16:40:43.431926Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_data_path = \"/kaggle/input/cs412-dataset/training-dataset.jsonl\"\n\nusername2posts_train = dict()\nusername2profile_train = dict()\n\nusername2posts_test = dict()\nusername2profile_test = dict()\n\n\nwith open(train_data_path, \"rt\") as fh:\n  for line in fh:\n    sample = json.loads(line)\n\n    profile = sample[\"profile\"] # Everything is under here except for posts\n    username = profile[\"username\"] #Get the username\n    if username in username2_category: #We already know the category for this user.\n      # train data info\n      username2posts_train[username] = sample[\"posts\"]\n      username2profile_train[username] = profile #Add the profile data into this dictionary\n\n\n    else:\n      # it is test data info\n      username2posts_test[username] = sample[\"posts\"]\n      username2profile_test[username] = profile\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:43.433478Z","iopub.execute_input":"2025-01-12T16:40:43.433709Z","iopub.status.idle":"2025-01-12T16:40:51.539525Z","shell.execute_reply.started":"2025-01-12T16:40:43.433689Z","shell.execute_reply":"2025-01-12T16:40:51.538815Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Profile Dataframe\ntrain_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\ntest_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n\ntrain_profile_df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.541858Z","iopub.execute_input":"2025-01-12T16:40:51.542120Z","iopub.status.idle":"2025-01-12T16:40:51.720189Z","shell.execute_reply.started":"2025-01-12T16:40:51.542075Z","shell.execute_reply":"2025-01-12T16:40:51.719465Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"     username          id    full_name  \\\n0  deparmedya  3170700063  Depar Medya   \n1  kafesfirin   266439571  KAFES FIRIN   \n\n                                           biography   category_name  \\\n0           #mediaplanning #mediabuying #sosyalmedya  Local business   \n1  ğŸ“SoÌˆgÌ†uÌˆtoÌˆzuÌˆğŸ“FTZ AVM\\nğŸ›’Ankara macroâ–²center v...           Brand   \n\n  post_count follower_count following_count is_business_account is_private  \\\n0       None           1167             192                True      False   \n1       None          11997              17                True      False   \n\n   ... business_category_name overall_category_name category_enum  \\\n0  ...                   None                  None         LOCAL   \n1  ...                   None                  None         BRAND   \n\n  is_verified_by_mv4b is_regulated_c18  \\\n0               False            False   \n1               False            False   \n\n                                     profile_pic_url should_show_category  \\\n0  https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....                 True   \n1  https://instagram.fada1-13.fna.fbcdn.net/v/t51...                 True   \n\n  should_show_public_contacts show_account_transparency_details  \\\n0                        True                              True   \n1                        True                              True   \n\n                              profile_picture_base64  \n0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n\n[2 rows x 44 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>id</th>\n      <th>full_name</th>\n      <th>biography</th>\n      <th>category_name</th>\n      <th>post_count</th>\n      <th>follower_count</th>\n      <th>following_count</th>\n      <th>is_business_account</th>\n      <th>is_private</th>\n      <th>...</th>\n      <th>business_category_name</th>\n      <th>overall_category_name</th>\n      <th>category_enum</th>\n      <th>is_verified_by_mv4b</th>\n      <th>is_regulated_c18</th>\n      <th>profile_pic_url</th>\n      <th>should_show_category</th>\n      <th>should_show_public_contacts</th>\n      <th>show_account_transparency_details</th>\n      <th>profile_picture_base64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>deparmedya</td>\n      <td>3170700063</td>\n      <td>Depar Medya</td>\n      <td>#mediaplanning #mediabuying #sosyalmedya</td>\n      <td>Local business</td>\n      <td>None</td>\n      <td>1167</td>\n      <td>192</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>LOCAL</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kafesfirin</td>\n      <td>266439571</td>\n      <td>KAFES FIRIN</td>\n      <td>ğŸ“SoÌˆgÌ†uÌˆtoÌˆzuÌˆğŸ“FTZ AVM\\nğŸ›’Ankara macroâ–²center v...</td>\n      <td>Brand</td>\n      <td>None</td>\n      <td>11997</td>\n      <td>17</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>BRAND</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fada1-13.fna.fbcdn.net/v/t51...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 44 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"test_profile_df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.721539Z","iopub.execute_input":"2025-01-12T16:40:51.721751Z","iopub.status.idle":"2025-01-12T16:40:51.735806Z","shell.execute_reply.started":"2025-01-12T16:40:51.721733Z","shell.execute_reply":"2025-01-12T16:40:51.735033Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                     username          id                    full_name  \\\n0              beyazyakaliyiz  8634457436           Selam Beyaz YakalÄ±   \n1  totalenergies_istasyonlari  7066643793  TotalEnergies IÌ‡stasyonlarÄ±   \n\n                                           biography   category_name  \\\n0        Beyaz yakalÄ±larÄ±n dÃ¼nyasÄ±na hoÅŸgeldiniz ğŸ˜€ğŸ˜€ğŸ˜€   Personal blog   \n1  TotalEnergies Ä°stasyonlarÄ± resmi Instagram hes...  Energy Company   \n\n  post_count follower_count following_count is_business_account is_private  \\\n0       None           1265             665                True      False   \n1       None          28025               4                True      False   \n\n   ... business_category_name overall_category_name   category_enum  \\\n0  ...                   None                  None   PERSONAL_BLOG   \n1  ...                   None                  None  ENERGY_COMPANY   \n\n  is_verified_by_mv4b is_regulated_c18  \\\n0               False            False   \n1               False            False   \n\n                                     profile_pic_url should_show_category  \\\n0  https://instagram.fist6-1.fna.fbcdn.net/v/t51....                 True   \n1  https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....                 True   \n\n  should_show_public_contacts show_account_transparency_details  \\\n0                        True                              True   \n1                        True                              True   \n\n                              profile_picture_base64  \n0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n\n[2 rows x 44 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>id</th>\n      <th>full_name</th>\n      <th>biography</th>\n      <th>category_name</th>\n      <th>post_count</th>\n      <th>follower_count</th>\n      <th>following_count</th>\n      <th>is_business_account</th>\n      <th>is_private</th>\n      <th>...</th>\n      <th>business_category_name</th>\n      <th>overall_category_name</th>\n      <th>category_enum</th>\n      <th>is_verified_by_mv4b</th>\n      <th>is_regulated_c18</th>\n      <th>profile_pic_url</th>\n      <th>should_show_category</th>\n      <th>should_show_public_contacts</th>\n      <th>show_account_transparency_details</th>\n      <th>profile_picture_base64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>beyazyakaliyiz</td>\n      <td>8634457436</td>\n      <td>Selam Beyaz YakalÄ±</td>\n      <td>Beyaz yakalÄ±larÄ±n dÃ¼nyasÄ±na hoÅŸgeldiniz ğŸ˜€ğŸ˜€ğŸ˜€</td>\n      <td>Personal blog</td>\n      <td>None</td>\n      <td>1265</td>\n      <td>665</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>PERSONAL_BLOG</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fist6-1.fna.fbcdn.net/v/t51....</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>totalenergies_istasyonlari</td>\n      <td>7066643793</td>\n      <td>TotalEnergies IÌ‡stasyonlarÄ±</td>\n      <td>TotalEnergies Ä°stasyonlarÄ± resmi Instagram hes...</td>\n      <td>Energy Company</td>\n      <td>None</td>\n      <td>28025</td>\n      <td>4</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>ENERGY_COMPANY</td>\n      <td>False</td>\n      <td>False</td>\n      <td>https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 44 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print(\"Profile DataFrame Columns:\", train_profile_df.columns.tolist())\nprint(\"Count is:\", len(train_profile_df.columns))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.736622Z","iopub.execute_input":"2025-01-12T16:40:51.736873Z","iopub.status.idle":"2025-01-12T16:40:51.749845Z","shell.execute_reply.started":"2025-01-12T16:40:51.736853Z","shell.execute_reply":"2025-01-12T16:40:51.749077Z"}},"outputs":[{"name":"stdout","text":"Profile DataFrame Columns: ['username', 'id', 'full_name', 'biography', 'category_name', 'post_count', 'follower_count', 'following_count', 'is_business_account', 'is_private', 'is_verified', 'highlight_reel_count', 'bio_links', 'entities', 'ai_agent_type', 'fb_profile_biolink', 'restricted_by_viewer', 'country_block', 'eimu_id', 'external_url', 'fbid', 'has_clips', 'hide_like_and_view_counts', 'is_professional_account', 'is_supervision_enabled', 'is_guardian_of_viewer', 'is_supervised_by_viewer', 'is_supervised_user', 'is_embeds_disabled', 'is_joined_recently', 'business_address_json', 'business_contact_method', 'business_email', 'business_phone_number', 'business_category_name', 'overall_category_name', 'category_enum', 'is_verified_by_mv4b', 'is_regulated_c18', 'profile_pic_url', 'should_show_category', 'should_show_public_contacts', 'show_account_transparency_details', 'profile_picture_base64']\nCount is: 44\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"username2posts_train[\"deparmedya\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.750548Z","iopub.execute_input":"2025-01-12T16:40:51.750764Z","iopub.status.idle":"2025-01-12T16:40:51.767557Z","shell.execute_reply.started":"2025-01-12T16:40:51.750738Z","shell.execute_reply":"2025-01-12T16:40:51.766881Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'caption': 'Cumhuriyetimizin 100.yÄ±lÄ± kutlu olsunâ™¾ï¸ğŸ‡¹ğŸ‡·',\n 'comments_count': 0,\n 'id': '17990918969458720',\n 'like_count': 6,\n 'media_type': 'IMAGE',\n 'media_url': 'https://scontent-sof1-2.cdninstagram.com/v/t51.29350-15/396342908_267936919574308_4264417069827989599_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=c4dd86&_nc_ohc=IynXuQSoOT8AX9RSy20&_nc_ht=scontent-sof1-2.cdninstagram.com&edm=AL-3X8kEAAAA&oh=00_AfA8OKAM0MY9tqg6dw8C8I5TJp4SHPBp-VlNXrFAh2agqg&oe=6563581C',\n 'timestamp': '2023-10-29 09:12:30'}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"list(username2posts_train[\"deparmedya\"][0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.768325Z","iopub.execute_input":"2025-01-12T16:40:51.768575Z","iopub.status.idle":"2025-01-12T16:40:51.782313Z","shell.execute_reply.started":"2025-01-12T16:40:51.768546Z","shell.execute_reply":"2025-01-12T16:40:51.781541Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['caption',\n 'comments_count',\n 'id',\n 'like_count',\n 'media_type',\n 'media_url',\n 'timestamp']"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"username = \"deparmedya\"\nuser_profile = username2profile_train.get(username, {})\nbiography = user_profile.get(\"biography\", \"\")\nprint(preprocess(biography))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.783214Z","iopub.execute_input":"2025-01-12T16:40:51.783491Z","iopub.status.idle":"2025-01-12T16:40:51.797100Z","shell.execute_reply.started":"2025-01-12T16:40:51.783464Z","shell.execute_reply":"2025-01-12T16:40:51.796320Z"}},"outputs":[{"name":"stdout","text":"<hashtag> mediaplanning </hashtag> <hashtag> mediabuying </hashtag> <hashtag> sosyalmedya </hashtag>\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nimport emoji\nfrom scipy.sparse import hstack\n\n\n# to keep the label order\ntrain_usernames = []\ntrain_caption_bio_combined = []\ntrain_captions = []\ntrain_bio = []\n\nmax_total_tokens_for_user_captions = 0 # To keep the total number of tokens, if > 128, then we need to do something.\nfor username, posts in username2posts_train.items():\n  train_usernames.append(username)\n  user_profile = username2profile_train.get(username, {})\n  user_biography = user_profile.get(\"biography\") or \"\"\n  user_biography = preprocess(user_biography) #using the preprocessor of the model\n  train_bio.append(user_biography)\n  # aggregating the posts per user\n  cleaned_captions = []\n  for post in posts:\n    post_caption = post.get(\"caption\", \"\")\n    if post_caption is None:\n      continue\n    post_caption = preprocess(post_caption)\n    if post_caption != \"\":\n      cleaned_captions.append(post_caption)\n  user_post_captions = \" \".join(cleaned_captions)\n  if not user_post_captions.strip():\n    print(\"User \" + username + \" from training has empty captions.\")\n\n  train_captions.append(user_post_captions)\n\ny_train = [username2_category.get(uname, \"NA\").lower() for uname in train_usernames]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:40:51.797775Z","iopub.execute_input":"2025-01-12T16:40:51.797987Z","iopub.status.idle":"2025-01-12T16:45:00.855686Z","shell.execute_reply.started":"2025-01-12T16:40:51.797969Z","shell.execute_reply":"2025-01-12T16:45:00.855000Z"}},"outputs":[{"name":"stdout","text":"User birguzeladam from training has empty captions.\nUser touchdownistanbul from training has empty captions.\nUser mks_kilit_sistemleri from training has empty captions.\nUser belediyesikose from training has empty captions.\nUser esqtekstil from training has empty captions.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"len(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.856536Z","iopub.execute_input":"2025-01-12T16:45:00.856824Z","iopub.status.idle":"2025-01-12T16:45:00.861728Z","shell.execute_reply.started":"2025-01-12T16:45:00.856795Z","shell.execute_reply":"2025-01-12T16:45:00.861037Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"2741"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"train_captions[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.862443Z","iopub.execute_input":"2025-01-12T16:45:00.862708Z","iopub.status.idle":"2025-01-12T16:45:00.881615Z","shell.execute_reply.started":"2025-01-12T16:45:00.862689Z","shell.execute_reply":"2025-01-12T16:45:00.880991Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"cumhuriyetimizin 100.yÄ±lÄ± kutlu olsun <emoji> sonsuzluk </emoji> <emoji> bayrak_tunus </emoji> oriflame duologi lansmanÄ± <hashtag> isveÃ§tengelengÃ¼zellik </hashtag> <hashtag> oriflameilesaÃ§bakÄ±mdevrimi </hashtag> <hashtag> oriflameilesaÃ§bakÄ±mdevrimi </hashtag> <emoji> sÄ±kÄ±ÅŸtÄ±ran_el_koyu_ten_tonu </emoji> <emoji> sÄ±kÄ±ÅŸtÄ±ran_el_koyu_ten_tonu </emoji> <hashtag> oriflameilesaÃ§bakÄ±mdevrimi </hashtag> 07agustosâ€™23 oriflameturkiye 07 agustosâ€™23 <hashtag> oriflameturkiye </hashtag> <hashtag> duoloji </hashtag> oriflame <hashtag> duoloji </hashtag> muhteÅŸem saÃ§larÄ±n sÄ±rrÄ± <hashtag> duoloji </hashtag> oriflameturkiye goe elektirikli motorsiklet ile , sÃ¼rdÃ¼rÃ¼lebilir bir yaÅŸamÄ±n elÃ§isi olun! <hashtag> goeilegeleceÄŸeyÃ¶nver </hashtag> <hashtag> goeilesÃ¼rdÃ¼rÃ¼lebilirgelecek </hashtag> <hashtag> easytorideeasytolove </hashtag> goe_mobility <emoji> motosiklet </emoji> 7 haziranâ€™23 <hashtag> yazamerhaba </hashtag> feridaistanbul 7 haziranâ€™23 <hashtag> yazamerhaba </hashtag> feridaistanbul <hashtag> yazamerhaba </hashtag> <emoji> sÄ±kÄ±ÅŸtÄ±ran_el_koyu_ten_tonu </emoji> <emoji> kiraz_Ã§iÃ§eÄŸi </emoji> feridacadde jumbopatisserie'nin 'edible artâ€™ konseptiyle Ã¶zel olarak hazÄ±rlanan tatlÄ±larÄ± ve baci milano'nun ÅŸÄ±k ve renkli dÃ¼nyasÄ±nda kahvaltÄ±dayÄ±z <hashtag> jumboturkiye </hashtag> easy to love, easy to ride <emoji> kÄ±rmÄ±zÄ±_kalp </emoji> goe_mobility figamortr mustafa kemal atatÃ¼rk'Ã¼ sevgi,saygÄ± ve Ã¶zlemle anÄ±yoruz. notecosmetiqueturkiye <hashtag> event </hashtag> <hashtag> kendimenote </hashtag> notecosmetiqueturkiye otoshops outdoor Ã§alÄ±ÅŸmalarÄ± otoshopsturkiye mad parfÃ¼m outdoor Ã§alÄ±ÅŸmalarÄ±mÄ±z madparfumeurofficial <hashtag> aÃ§Ä±khavareklam </hashtag> <hashtag> letsgetmad </hashtag> notecosmetiqueturkiye <hashtag> kendimenote </hashtag> note cosmetique aÃ§Ä±khava <emoji> parÄ±ldÄ±yor </emoji> note cosmetique etkinliÄŸinden <emoji> balon </emoji> cumhuriyet bayramÄ±nÄ±z kutlu olsun <emoji> bayrak_tunus </emoji> geÃ§miÅŸ olsun tÃ¼rkiye <emoji> katlanmÄ±ÅŸ_eller </emoji> kurban bayramÄ±nÄ±z kutlu olsun <emoji> gÃ¼len_yÃ¼z </emoji> â€œdÃ¼nyada her ÅŸey kadÄ±nÄ±n eseridir.â€ mustafa kemal atatÃ¼rk sizin gibi gÃ¼Ã§lÃ¼, mÃ¼cadeleci ve emekÃ§i bir kadÄ±nÄ±n bÃ¼tÃ¼n dÃ¼nya kadÄ±nlarÄ±na Ã¶rnek olmasÄ± dileÄŸiyle <emoji> kÄ±rmÄ±zÄ±_kalp </emoji> 8 mart dÃ¼nya emekÃ§i kadÄ±nlar gÃ¼nÃ¼ kutlu olsun. depar medya ekibi <hashtag> 8martdÃ¼nyakadÄ±nlargÃ¼nÃ¼ </hashtag> Ã¶ÄŸretmenler gÃ¼nÃ¼ kutlu olsun. <hashtag> 24kasÄ±mÃ¶ÄŸretmenlergÃ¼nÃ¼ </hashtag> <hashtag> deparmedya </hashtag> pruvada tek eksik sizâ€™siniz. pruva.34 burcues <hashtag> deparmedya </hashtag> saygÄ± ve Ã¶zlemle anÄ±yoruz... <hashtag> 10kasÄ±m </hashtag> <hashtag> atatÃ¼rk </hashtag> geÃ§miÅŸ olsun iÌ‡zmir <emoji> katlanmÄ±ÅŸ_eller </emoji> dualarÄ±mÄ±z sizinle. cumhuriyetimiz bugÃ¼n 97 yaÅŸÄ±nda! 29 ekim cumhuriyet bayramÄ±â€™mÄ±z kutlu olsun! <emoji> bayrak_tunus </emoji> finlandiya'da ÅŸehrin kadÄ±na yÃ¶nelik ÅŸiddet hakkÄ±nda bir farkÄ±ndalÄ±k kampanyasÄ±! helsinkiâ€™nin merkezinde yer alan havis amanda heykeli, ÅŸehrin en ikonik sanat eserlerinden biri olmasÄ±nÄ±n yanÄ± sÄ±ra talihsiz bir Ã¶zelliÄŸe de sahip. 100 yÄ±lÄ± deviren heykel, sÄ±k sÄ±k ÅŸehirdeki kutlamalarÄ±n ortasÄ±nda kalÄ±yor ve Ã§oÄŸunluÄŸunu erkeklerin oluÅŸturduÄŸu insanlarÄ±n tÄ±rmanÄ±ÅŸlarÄ±na maruz kalÄ±yor. yÄ±kÄ±lma tehlikesi bulunan heykelin en kÄ±rÄ±lgan kÄ±smÄ± ise boyun bÃ¶lgesi. Ã¼lkedeki ÅŸiddet maÄŸdurlarÄ±na yardÄ±m eli uzatan nollalinja, bu yÄ±l kadÄ±na yÃ¶nelik ÅŸiddete karÅŸÄ± uluslararasÄ± mÃ¼cadele ve dayanÄ±ÅŸma gÃ¼nÃ¼â€™nde havis amandaâ€™ya bir boyunluk yerleÅŸtirdi. bÃ¶ylece, ÅŸehrin ikonik heykeli kadÄ±na yÃ¶nelik ÅŸiddete karÅŸÄ± bir uyarÄ± sembolÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼. tÃ¼rkiye vodafone vakfÄ±, eÄŸitime destek iÃ§in herkesi twitter hesaplarÄ±nÄ± baÄŸÄ±ÅŸlamaya davet ediyor! tÃ¼rkiye vodafone vakfÄ±, dijital geleceÄŸe hazÄ±r nesiller yetiÅŸtirilmesi hedefiyle habitat derneÄŸi iÅŸbirliÄŸiyle hayata geÃ§irdiÄŸi yarÄ±nÄ± kodlayanlar projesi kapsamÄ±nda <hashtag> hesabÄ±mkitapolsun </hashtag> etiketiyle yeni bir sosyal medya kampanyasÄ± baÅŸlattÄ±. Ã§ocuklarÄ±n eÄŸitimine destek olmak amacÄ±yla twitter Ã¼zerinden hayata geÃ§irilen kitap baÄŸÄ±ÅŸÄ± kapsamÄ±nda, <hashtag> hesabÄ±mkitapolsun </hashtag> etiketiyle tweet atan kullanÄ±cÄ±lar, bir anlamda twitter hesaplarÄ±nÄ± baÄŸÄ±ÅŸlamÄ±ÅŸ olacak. <hashtag> hesabÄ±mkitapolsun </hashtag> etiketiyle tweet atan bir kullanÄ±cÄ±nÄ±n hesabÄ±ndaki toplam kelime sayÄ±sÄ±na en yakÄ±n sayÄ±da kelimeye sahip bir kitap, kullanÄ±cÄ± adÄ±na bir okula baÄŸÄ±ÅŸlanacak. huawei watch gt 2'den hiÃ§ Ã§Ä±karÄ±lmayacak saat! p smart 2019 ve p30 serisi akÄ±llÄ± telefonlarÄ±nÄ±n reklamlarÄ±nÄ± tÃ¼rkiyeâ€™de Ã§eken huawei tÃ¼rkiye, kampanyalarÄ±ndaki yerel bakÄ±ÅŸ aÃ§Ä±sÄ±nÄ± yeni nesil akÄ±llÄ± saati huawei watch gt 2 iÃ§in hazÄ±rladÄ±ÄŸÄ± reklam filmiyle sÃ¼rdÃ¼rÃ¼yor. â€œhiÃ§ Ã§Ä±karmaâ€ adlÄ± kampanya kapsamÄ±nda watch gt 2 iÃ§in hazÄ±rlanan filmde beyaz yakalÄ± genÃ§ler Ã¼zerinden, watch gt 2â€™nin haftalarca sÃ¼ren pil performansÄ±na ve gÃ¼nlÃ¼k hayatta saÄŸladÄ±ÄŸÄ± faydalara odaklanÄ±lÄ±yor. beyaz yakalÄ± genÃ§ profesyonellerin gÃ¼nlÃ¼k sÃ¼reÃ§lerinin incelenmesinin ardÄ±ndan gÃ¶zlemlenen trendlere uygun olarak hazÄ±rlanan filmde genÃ§lerin hem yaÅŸam asistanÄ± hem saÄŸlÄ±k takipÃ§isi hem de kiÅŸisel antrenÃ¶rÃ¼ olan watch gt 2â€™yi takanlar, onu hiÃ§ Ã§Ä±karmÄ±yor.\""},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"train_bio[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.882304Z","iopub.execute_input":"2025-01-12T16:45:00.882511Z","iopub.status.idle":"2025-01-12T16:45:00.895339Z","shell.execute_reply.started":"2025-01-12T16:45:00.882487Z","shell.execute_reply":"2025-01-12T16:45:00.894705Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'<hashtag> mediaplanning </hashtag> <hashtag> mediabuying </hashtag> <hashtag> sosyalmedya </hashtag>'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"train_usernames[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.896010Z","iopub.execute_input":"2025-01-12T16:45:00.896257Z","iopub.status.idle":"2025-01-12T16:45:00.910866Z","shell.execute_reply.started":"2025-01-12T16:45:00.896237Z","shell.execute_reply":"2025-01-12T16:45:00.910079Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'deparmedya'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"categories = [\n    'mom and children',\n    'food',\n    'travel',\n    'gaming',\n    'fashion',\n    'health and lifestyle',\n    'tech',\n    'entertainment',\n    'sports',\n    'art'\n]\n\n# Create label2id and id2label\nlabel2id = {label: idx for idx, label in enumerate(categories)}\nid2label = {idx: label for idx, label in enumerate(categories)}\n\nprint(\"label2id:\", label2id)\nprint(\"id2label:\", id2label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.911662Z","iopub.execute_input":"2025-01-12T16:45:00.911868Z","iopub.status.idle":"2025-01-12T16:45:00.926307Z","shell.execute_reply.started":"2025-01-12T16:45:00.911849Z","shell.execute_reply":"2025-01-12T16:45:00.925508Z"}},"outputs":[{"name":"stdout","text":"label2id: {'mom and children': 0, 'food': 1, 'travel': 2, 'gaming': 3, 'fashion': 4, 'health and lifestyle': 5, 'tech': 6, 'entertainment': 7, 'sports': 8, 'art': 9}\nid2label: {0: 'mom and children', 1: 'food', 2: 'travel', 3: 'gaming', 4: 'fashion', 5: 'health and lifestyle', 6: 'tech', 7: 'entertainment', 8: 'sports', 9: 'art'}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"len(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.927080Z","iopub.execute_input":"2025-01-12T16:45:00.927353Z","iopub.status.idle":"2025-01-12T16:45:00.942077Z","shell.execute_reply.started":"2025-01-12T16:45:00.927334Z","shell.execute_reply":"2025-01-12T16:45:00.941493Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer\n)\nfrom datasets import Dataset\n\nfrom peft import (\n    PeftModel,\n    PeftConfig,\n)\n\ntexts = []\nfor bio, caption in zip(train_bio, train_captions):\n    combined_text = bio.strip() + \" \" + caption.strip()\n    texts.append(combined_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:00.942758Z","iopub.execute_input":"2025-01-12T16:45:00.943022Z","iopub.status.idle":"2025-01-12T16:45:09.188737Z","shell.execute_reply.started":"2025-01-12T16:45:00.943002Z","shell.execute_reply":"2025-01-12T16:45:09.187927Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"numeric_labels = [label2id[label_str] for label_str in y_train]\nlen(numeric_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:09.189594Z","iopub.execute_input":"2025-01-12T16:45:09.190109Z","iopub.status.idle":"2025-01-12T16:45:09.195714Z","shell.execute_reply.started":"2025-01-12T16:45:09.190071Z","shell.execute_reply":"2025-01-12T16:45:09.194946Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"2741"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"texts[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:09.196398Z","iopub.execute_input":"2025-01-12T16:45:09.196710Z","iopub.status.idle":"2025-01-12T16:45:09.216639Z","shell.execute_reply.started":"2025-01-12T16:45:09.196684Z","shell.execute_reply":"2025-01-12T16:45:09.216011Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"<hashtag> mediaplanning </hashtag> <hashtag> mediabuying </hashtag> <hashtag> sosyalmedya </hashtag> cumhuriyetimizin 100.yÄ±lÄ± kutlu olsun <emoji> sonsuzluk </emoji> <emoji> bayrak_tunus </emoji> oriflame duologi lansmanÄ± <hashtag> isveÃ§tengelengÃ¼zellik </hashtag> <hashtag> oriflameilesaÃ§bakÄ±mdevrimi </hashtag> <hashtag> oriflameilesaÃ§bakÄ±mdevrimi </hashtag> <emoji> sÄ±kÄ±ÅŸtÄ±ran_el_koyu_ten_tonu </emoji> <emoji> sÄ±kÄ±ÅŸtÄ±ran_el_koyu_ten_tonu </emoji> <hashtag> oriflameilesaÃ§bakÄ±mdevrimi </hashtag> 07agustosâ€™23 oriflameturkiye 07 agustosâ€™23 <hashtag> oriflameturkiye </hashtag> <hashtag> duoloji </hashtag> oriflame <hashtag> duoloji </hashtag> muhteÅŸem saÃ§larÄ±n sÄ±rrÄ± <hashtag> duoloji </hashtag> oriflameturkiye goe elektirikli motorsiklet ile , sÃ¼rdÃ¼rÃ¼lebilir bir yaÅŸamÄ±n elÃ§isi olun! <hashtag> goeilegeleceÄŸeyÃ¶nver </hashtag> <hashtag> goeilesÃ¼rdÃ¼rÃ¼lebilirgelecek </hashtag> <hashtag> easytorideeasytolove </hashtag> goe_mobility <emoji> motosiklet </emoji> 7 haziranâ€™23 <hashtag> yazamerhaba </hashtag> feridaistanbul 7 haziranâ€™23 <hashtag> yazamerhaba </hashtag> feridaistanbul <hashtag> yazamerhaba </hashtag> <emoji> sÄ±kÄ±ÅŸtÄ±ran_el_koyu_ten_tonu </emoji> <emoji> kiraz_Ã§iÃ§eÄŸi </emoji> feridacadde jumbopatisserie'nin 'edible artâ€™ konseptiyle Ã¶zel olarak hazÄ±rlanan tatlÄ±larÄ± ve baci milano'nun ÅŸÄ±k ve renkli dÃ¼nyasÄ±nda kahvaltÄ±dayÄ±z <hashtag> jumboturkiye </hashtag> easy to love, easy to ride <emoji> kÄ±rmÄ±zÄ±_kalp </emoji> goe_mobility figamortr mustafa kemal atatÃ¼rk'Ã¼ sevgi,saygÄ± ve Ã¶zlemle anÄ±yoruz. notecosmetiqueturkiye <hashtag> event </hashtag> <hashtag> kendimenote </hashtag> notecosmetiqueturkiye otoshops outdoor Ã§alÄ±ÅŸmalarÄ± otoshopsturkiye mad parfÃ¼m outdoor Ã§alÄ±ÅŸmalarÄ±mÄ±z madparfumeurofficial <hashtag> aÃ§Ä±khavareklam </hashtag> <hashtag> letsgetmad </hashtag> notecosmetiqueturkiye <hashtag> kendimenote </hashtag> note cosmetique aÃ§Ä±khava <emoji> parÄ±ldÄ±yor </emoji> note cosmetique etkinliÄŸinden <emoji> balon </emoji> cumhuriyet bayramÄ±nÄ±z kutlu olsun <emoji> bayrak_tunus </emoji> geÃ§miÅŸ olsun tÃ¼rkiye <emoji> katlanmÄ±ÅŸ_eller </emoji> kurban bayramÄ±nÄ±z kutlu olsun <emoji> gÃ¼len_yÃ¼z </emoji> â€œdÃ¼nyada her ÅŸey kadÄ±nÄ±n eseridir.â€ mustafa kemal atatÃ¼rk sizin gibi gÃ¼Ã§lÃ¼, mÃ¼cadeleci ve emekÃ§i bir kadÄ±nÄ±n bÃ¼tÃ¼n dÃ¼nya kadÄ±nlarÄ±na Ã¶rnek olmasÄ± dileÄŸiyle <emoji> kÄ±rmÄ±zÄ±_kalp </emoji> 8 mart dÃ¼nya emekÃ§i kadÄ±nlar gÃ¼nÃ¼ kutlu olsun. depar medya ekibi <hashtag> 8martdÃ¼nyakadÄ±nlargÃ¼nÃ¼ </hashtag> Ã¶ÄŸretmenler gÃ¼nÃ¼ kutlu olsun. <hashtag> 24kasÄ±mÃ¶ÄŸretmenlergÃ¼nÃ¼ </hashtag> <hashtag> deparmedya </hashtag> pruvada tek eksik sizâ€™siniz. pruva.34 burcues <hashtag> deparmedya </hashtag> saygÄ± ve Ã¶zlemle anÄ±yoruz... <hashtag> 10kasÄ±m </hashtag> <hashtag> atatÃ¼rk </hashtag> geÃ§miÅŸ olsun iÌ‡zmir <emoji> katlanmÄ±ÅŸ_eller </emoji> dualarÄ±mÄ±z sizinle. cumhuriyetimiz bugÃ¼n 97 yaÅŸÄ±nda! 29 ekim cumhuriyet bayramÄ±â€™mÄ±z kutlu olsun! <emoji> bayrak_tunus </emoji> finlandiya'da ÅŸehrin kadÄ±na yÃ¶nelik ÅŸiddet hakkÄ±nda bir farkÄ±ndalÄ±k kampanyasÄ±! helsinkiâ€™nin merkezinde yer alan havis amanda heykeli, ÅŸehrin en ikonik sanat eserlerinden biri olmasÄ±nÄ±n yanÄ± sÄ±ra talihsiz bir Ã¶zelliÄŸe de sahip. 100 yÄ±lÄ± deviren heykel, sÄ±k sÄ±k ÅŸehirdeki kutlamalarÄ±n ortasÄ±nda kalÄ±yor ve Ã§oÄŸunluÄŸunu erkeklerin oluÅŸturduÄŸu insanlarÄ±n tÄ±rmanÄ±ÅŸlarÄ±na maruz kalÄ±yor. yÄ±kÄ±lma tehlikesi bulunan heykelin en kÄ±rÄ±lgan kÄ±smÄ± ise boyun bÃ¶lgesi. Ã¼lkedeki ÅŸiddet maÄŸdurlarÄ±na yardÄ±m eli uzatan nollalinja, bu yÄ±l kadÄ±na yÃ¶nelik ÅŸiddete karÅŸÄ± uluslararasÄ± mÃ¼cadele ve dayanÄ±ÅŸma gÃ¼nÃ¼â€™nde havis amandaâ€™ya bir boyunluk yerleÅŸtirdi. bÃ¶ylece, ÅŸehrin ikonik heykeli kadÄ±na yÃ¶nelik ÅŸiddete karÅŸÄ± bir uyarÄ± sembolÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼. tÃ¼rkiye vodafone vakfÄ±, eÄŸitime destek iÃ§in herkesi twitter hesaplarÄ±nÄ± baÄŸÄ±ÅŸlamaya davet ediyor! tÃ¼rkiye vodafone vakfÄ±, dijital geleceÄŸe hazÄ±r nesiller yetiÅŸtirilmesi hedefiyle habitat derneÄŸi iÅŸbirliÄŸiyle hayata geÃ§irdiÄŸi yarÄ±nÄ± kodlayanlar projesi kapsamÄ±nda <hashtag> hesabÄ±mkitapolsun </hashtag> etiketiyle yeni bir sosyal medya kampanyasÄ± baÅŸlattÄ±. Ã§ocuklarÄ±n eÄŸitimine destek olmak amacÄ±yla twitter Ã¼zerinden hayata geÃ§irilen kitap baÄŸÄ±ÅŸÄ± kapsamÄ±nda, <hashtag> hesabÄ±mkitapolsun </hashtag> etiketiyle tweet atan kullanÄ±cÄ±lar, bir anlamda twitter hesaplarÄ±nÄ± baÄŸÄ±ÅŸlamÄ±ÅŸ olacak. <hashtag> hesabÄ±mkitapolsun </hashtag> etiketiyle tweet atan bir kullanÄ±cÄ±nÄ±n hesabÄ±ndaki toplam kelime sayÄ±sÄ±na en yakÄ±n sayÄ±da kelimeye sahip bir kitap, kullanÄ±cÄ± adÄ±na bir okula baÄŸÄ±ÅŸlanacak. huawei watch gt 2'den hiÃ§ Ã§Ä±karÄ±lmayacak saat! p smart 2019 ve p30 serisi akÄ±llÄ± telefonlarÄ±nÄ±n reklamlarÄ±nÄ± tÃ¼rkiyeâ€™de Ã§eken huawei tÃ¼rkiye, kampanyalarÄ±ndaki yerel bakÄ±ÅŸ aÃ§Ä±sÄ±nÄ± yeni nesil akÄ±llÄ± saati huawei watch gt 2 iÃ§in hazÄ±rladÄ±ÄŸÄ± reklam filmiyle sÃ¼rdÃ¼rÃ¼yor. â€œhiÃ§ Ã§Ä±karmaâ€ adlÄ± kampanya kapsamÄ±nda watch gt 2 iÃ§in hazÄ±rlanan filmde beyaz yakalÄ± genÃ§ler Ã¼zerinden, watch gt 2â€™nin haftalarca sÃ¼ren pil performansÄ±na ve gÃ¼nlÃ¼k hayatta saÄŸladÄ±ÄŸÄ± faydalara odaklanÄ±lÄ±yor. beyaz yakalÄ± genÃ§ profesyonellerin gÃ¼nlÃ¼k sÃ¼reÃ§lerinin incelenmesinin ardÄ±ndan gÃ¶zlemlenen trendlere uygun olarak hazÄ±rlanan filmde genÃ§lerin hem yaÅŸam asistanÄ± hem saÄŸlÄ±k takipÃ§isi hem de kiÅŸisel antrenÃ¶rÃ¼ olan watch gt 2â€™yi takanlar, onu hiÃ§ Ã§Ä±karmÄ±yor.\""},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"model_name = \"dbmdz/bert-base-turkish-uncased\"\n# model_name = \"dbmdz/bert-base-turkish-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=10,            # <-- your 10 labels\n    id2label=id2label,\n    label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:09.217423Z","iopub.execute_input":"2025-01-12T16:45:09.217709Z","iopub.status.idle":"2025-01-12T16:45:13.759700Z","shell.execute_reply.started":"2025-01-12T16:45:09.217681Z","shell.execute_reply":"2025-01-12T16:45:13.759067Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8d4cacc22944758bca395881bec0f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa7b18485b440f187076ffe21dac9fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da47cb943ea4d91995be2c5a1105074"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0c320eb4f849af847ac19d5d177cbd"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Apply an 80-20 split\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    texts, numeric_labels, test_size=0.2, random_state=42\n)\n\n# Output the results\nprint(\"Train texts:\", len(train_texts))\nprint(\"Test texts:\", len(test_texts))\nprint(\"Train labels:\", len(train_labels))\nprint(\"Test labels:\", len(test_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:13.760512Z","iopub.execute_input":"2025-01-12T16:45:13.760795Z","iopub.status.idle":"2025-01-12T16:45:13.770249Z","shell.execute_reply.started":"2025-01-12T16:45:13.760763Z","shell.execute_reply":"2025-01-12T16:45:13.769427Z"}},"outputs":[{"name":"stdout","text":"Train texts: 2192\nTest texts: 549\nTrain labels: 2192\nTest labels: 549\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\ntest_dataset  = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:13.773838Z","iopub.execute_input":"2025-01-12T16:45:13.774037Z","iopub.status.idle":"2025-01-12T16:45:14.303784Z","shell.execute_reply.started":"2025-01-12T16:45:13.774020Z","shell.execute_reply":"2025-01-12T16:45:14.303121Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def chunk_text(examples, chunk_size=512):\n    \"\"\"\n    Splits each example's text into chunks of up to `chunk_size` words,\n    and replicates the label for each chunk.\n    \"\"\"\n    new_texts = []\n    new_labels = []\n\n    # examples[\"text\"] is now a *list* of strings\n    # examples[\"label\"] is now a *list* of labels\n    for text, label in zip(examples[\"text\"], examples[\"label\"]):\n        words = text.split()\n        for i in range(0, len(words), chunk_size):\n            chunk = \" \".join(words[i : i + chunk_size])\n            new_texts.append(chunk)\n            new_labels.append(label)\n\n    return {\"text\": new_texts, \"label\": new_labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:14.304864Z","iopub.execute_input":"2025-01-12T16:45:14.305163Z","iopub.status.idle":"2025-01-12T16:45:14.309852Z","shell.execute_reply.started":"2025-01-12T16:45:14.305139Z","shell.execute_reply":"2025-01-12T16:45:14.308952Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Apply chunking to train and test sets\ntrain_dataset = train_dataset.map(chunk_text, batched=True)\ntest_dataset  = test_dataset.map(chunk_text,  batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:14.310740Z","iopub.execute_input":"2025-01-12T16:45:14.310978Z","iopub.status.idle":"2025-01-12T16:45:15.296186Z","shell.execute_reply.started":"2025-01-12T16:45:14.310947Z","shell.execute_reply":"2025-01-12T16:45:15.295515Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2192 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ead30342645477984c63bda194e2840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/549 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6accd1d2dcb1458a97b2c41d73a5a8e5"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",  # or \"longest\", or dynamic padding\n        max_length=512         # or 256, or 512 depending on your data\n    )\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\n\n\n# The Trainer expects the columns \"input_ids\", \"attention_mask\", and \"labels\"\ntrain_dataset = train_dataset.rename_column(\"label\", \"labels\")\ntest_dataset = test_dataset.rename_column(\"label\", \"labels\")\n\n# set the format for PyTorch\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:15.297003Z","iopub.execute_input":"2025-01-12T16:45:15.297323Z","iopub.status.idle":"2025-01-12T16:45:30.958314Z","shell.execute_reply.started":"2025-01-12T16:45:15.297291Z","shell.execute_reply":"2025-01-12T16:45:30.957587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8420 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64682466d72041619d7ee649093e9eae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87fd885487d146b994a9f0b8d3044938"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"!pip install evaluate\nimport numpy as np\nfrom evaluate import load\nmetric = load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:45:30.959254Z","iopub.execute_input":"2025-01-12T16:45:30.959604Z","iopub.status.idle":"2025-01-12T16:45:36.259757Z","shell.execute_reply.started":"2025-01-12T16:45:30.959573Z","shell.execute_reply":"2025-01-12T16:45:36.258839Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8efaa2998e4e74bbf95ae11ba35482"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"from transformers import EarlyStoppingCallback\ntraining_args = TrainingArguments(\n    output_dir=\"best_performing_TurkishBERTweet\",\n    eval_strategy=\"steps\",    # Evaluate at regular steps\n    eval_steps=50,                  # Evaluation frequency\n    save_strategy=\"steps\",\n    save_steps=50,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,\n    logging_steps=10,               # Log every 10 steps\n    logging_dir=\"./logs\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    save_total_limit=1,\n    disable_tqdm=False,             # Enable progress bars\n    report_to=[\"none\"]              # Disable integration reports\n)\n# Initialize the EarlyStoppingCallback\nearly_stopping = EarlyStoppingCallback(\n    early_stopping_patience=3,      # Stop after 2 evaluations with no improvement\n    early_stopping_threshold=0.0    # Minimum change to qualify as improvement\n)\n\n# Ensure all model parameters are contiguous\nfor param in model.parameters():\n    param.data = param.data.contiguous()\n\nfrom torch.optim import AdamW\n\n# Define weight decay parameters\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\n        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.01,  # Adjust weight decay as needed\n    },\n    {\n        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\n\n# Initialize the optimizer with the custom learning rate\noptimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n\nfrom transformers import get_linear_schedule_with_warmup\n\n# Calculate the total number of training steps\nnum_epochs = training_args.num_train_epochs\nnum_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * num_epochs\n\n# Define the number of warmup steps\nnum_warmup_steps = int(0.1 * num_training_steps)  # 10% of training steps for warmup\n\n# Initialize the scheduler\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:47:08.566908Z","iopub.execute_input":"2025-01-12T16:47:08.567297Z","iopub.status.idle":"2025-01-12T16:47:08.951669Z","shell.execute_reply.started":"2025-01-12T16:47:08.567267Z","shell.execute_reply":"2025-01-12T16:47:08.950764Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"print(model)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,       # Include validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, lr_scheduler),  # Pass the optimizer and scheduler here\n    callbacks=[early_stopping]      # Add the early stopping callback\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:47:16.028280Z","iopub.execute_input":"2025-01-12T16:47:16.028618Z","iopub.status.idle":"2025-01-12T17:18:17.307442Z","shell.execute_reply.started":"2025-01-12T16:47:16.028589Z","shell.execute_reply":"2025-01-12T17:18:17.306501Z"}},"outputs":[{"name":"stdout","text":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=10, bias=True)\n)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1650' max='10530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1650/10530 30:59 < 2:46:58, 0.89 it/s, Epoch 1/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.385200</td>\n      <td>2.380813</td>\n      <td>0.063779</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.338500</td>\n      <td>2.308991</td>\n      <td>0.080438</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.198100</td>\n      <td>2.208130</td>\n      <td>0.194193</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.065000</td>\n      <td>2.145902</td>\n      <td>0.201333</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>2.091600</td>\n      <td>2.092469</td>\n      <td>0.265112</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.069800</td>\n      <td>2.067296</td>\n      <td>0.273203</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>2.043400</td>\n      <td>2.039759</td>\n      <td>0.286054</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.042600</td>\n      <td>1.985015</td>\n      <td>0.322703</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.894900</td>\n      <td>1.889013</td>\n      <td>0.365540</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.796700</td>\n      <td>1.723411</td>\n      <td>0.468348</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.635400</td>\n      <td>1.543910</td>\n      <td>0.536411</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.281400</td>\n      <td>1.392313</td>\n      <td>0.617325</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.255100</td>\n      <td>1.285407</td>\n      <td>0.619705</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.159900</td>\n      <td>1.192592</td>\n      <td>0.637792</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.035800</td>\n      <td>1.106131</td>\n      <td>0.663018</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.083000</td>\n      <td>1.087730</td>\n      <td>0.684436</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.075600</td>\n      <td>1.076131</td>\n      <td>0.672537</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.126500</td>\n      <td>1.059961</td>\n      <td>0.680628</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.158300</td>\n      <td>1.009003</td>\n      <td>0.686340</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.843300</td>\n      <td>1.052827</td>\n      <td>0.674441</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.030000</td>\n      <td>0.998015</td>\n      <td>0.692527</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.699000</td>\n      <td>0.981322</td>\n      <td>0.699667</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.848000</td>\n      <td>0.992672</td>\n      <td>0.697287</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.772000</td>\n      <td>0.996128</td>\n      <td>0.699191</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.905900</td>\n      <td>0.970958</td>\n      <td>0.714422</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.607700</td>\n      <td>0.974963</td>\n      <td>0.711566</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.128300</td>\n      <td>0.932735</td>\n      <td>0.714898</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.043900</td>\n      <td>0.960308</td>\n      <td>0.701095</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.727700</td>\n      <td>0.950306</td>\n      <td>0.712042</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.787200</td>\n      <td>0.935445</td>\n      <td>0.717277</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.800100</td>\n      <td>0.938195</td>\n      <td>0.702999</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.641000</td>\n      <td>0.960837</td>\n      <td>0.698239</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.792100</td>\n      <td>0.953524</td>\n      <td>0.699191</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1650, training_loss=1.352440616723263, metrics={'train_runtime': 1860.1332, 'train_samples_per_second': 45.266, 'train_steps_per_second': 5.661, 'total_flos': 3472262876995584.0, 'train_loss': 1.352440616723263, 'epoch': 1.566951566951567})"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"predictions = trainer.predict(test_dataset)\nprint(predictions.metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:27:23.407569Z","iopub.execute_input":"2025-01-12T17:27:23.407923Z","iopub.status.idle":"2025-01-12T17:27:54.959199Z","shell.execute_reply.started":"2025-01-12T17:27:23.407892Z","shell.execute_reply":"2025-01-12T17:27:54.958320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'test_loss': 0.9354445338249207, 'test_accuracy': 0.7172774869109948, 'test_runtime': 31.542, 'test_samples_per_second': 66.61, 'test_steps_per_second': 8.338}\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nimport emoji\nfrom scipy.sparse import hstack\n\n\n# to keep the label order\ntest_usernames = []\ntest_captions = []\ntest_bio = []\n\nfor username, posts in username2posts_test.items():\n  test_usernames.append(username)\n  user_profile = username2profile_test.get(username, {})\n  user_biography = user_profile.get(\"biography\") or \"\"\n  user_biography = preprocess(user_biography) #using the preprocessor of the model\n  test_bio.append(user_biography)\n  # aggregating the posts per user\n  cleaned_captions = []\n  for post in posts:\n    post_caption = post.get(\"caption\", \"\")\n    if post_caption is None:\n      continue\n    post_caption = preprocess(post_caption)\n    if post_caption != \"\":\n      cleaned_captions.append(post_caption)\n  user_post_captions = \" \".join(cleaned_captions)\n  if not user_post_captions.strip():\n    print(\"User \" + username + \" from test has empty captions.\")\n\n  test_captions.append(user_post_captions)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:41:46.864839Z","iopub.execute_input":"2025-01-12T17:41:46.865173Z","iopub.status.idle":"2025-01-12T17:46:17.019002Z","shell.execute_reply.started":"2025-01-12T17:41:46.865149Z","shell.execute_reply":"2025-01-12T17:46:17.018256Z"}},"outputs":[{"name":"stdout","text":"User sanatdan_ from test has empty captions.\nUser modamizbir from test has empty captions.\nUser deeprockbar35 from test has empty captions.\nUser flamingo_fashionn from test has empty captions.\nUser dogukandrl from test has empty captions.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"test_texts = []\nfor bio_text, captions_text in zip(test_bio, test_captions):\n    combined_text = bio_text.strip() + \" \" + captions_text.strip()\n    test_texts.append(combined_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:46:52.183513Z","iopub.execute_input":"2025-01-12T17:46:52.183818Z","iopub.status.idle":"2025-01-12T17:46:52.246769Z","shell.execute_reply.started":"2025-01-12T17:46:52.183794Z","shell.execute_reply":"2025-01-12T17:46:52.245837Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"test_texts[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:46:58.994987Z","iopub.execute_input":"2025-01-12T17:46:58.995488Z","iopub.status.idle":"2025-01-12T17:46:59.002081Z","shell.execute_reply.started":"2025-01-12T17:46:58.995450Z","shell.execute_reply":"2025-01-12T17:46:59.001188Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'beyaz yakalÄ±larÄ±n dÃ¼nyasÄ±na hoÅŸgeldiniz <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> bu diyaloÄŸun yaÅŸanmadÄ±ÄŸÄ± bir online toplantÄ± olmaz olamaz <emoji> sevinÃ§_gÃ¶zyaÅŸlarÄ±yla_yÃ¼zleÅŸmek </emoji> evet ocak ayÄ±nda beyaz yakalÄ± whatsup gruplarÄ±nda en Ã§ok sorulan soru, <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> hayÄ±r post gecikmeli deÄŸil, hala Ã¶ÄŸrenememiÅŸ olan binlerce kiÅŸi olduÄŸunu sÃ¶yleyebilirim ama ispat edemem <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> yine yuzlercesini gorecegimiz maillerden biri <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> iÌ‡yi haftalar ! <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> bir iÃ§ ses <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> 10 dk kahve iÃ§mek mi <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> geldi hesap kitap aylarÄ± <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> yaÅŸayan bilir. sen, ben, hepimiz <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> . . <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyaka </hashtag> <hashtag> beyazyakaliyiz </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> homeoffice </hashtag> yeni hafta yeni umutlar <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> beyazyaka </hashtag> yaz ayÄ±nÄ±n baÅŸlamasÄ± ile beyaz yakalÄ±larÄ±nda gÃ¼ney hayali sezonu aÃ§Ä±lmÄ±ÅŸtÄ±r, her tatil dÃ¶nÃ¼ÅŸÃ¼ dinleyeceÄŸimiz ah gitsek ne gÃ¼zel olurdu be diyaloglarÄ±na hazÄ±r mÄ±yÄ±z? <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> . . . <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> kurumsalhayat </hashtag> home office devam edenlerin Ã¶zlediÄŸi bazÄ± detaylar <emoji> sevinÃ§_gÃ¶zyaÅŸlarÄ±yla_yÃ¼zleÅŸmek </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . <hashtag> homeoffice </hashtag> <hashtag> officediaries </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakali </hashtag> <hashtag> beyazyaka </hashtag> <hashtag> beyazyakalilar </hashtag> toplantÄ±da lafÄ± aÄŸza tÄ±kÄ±lan, tam birÅŸey anlatÄ±rken sÃ¶zÃ¼ mÃ¼dÃ¼rÃ¼ tarafÄ±ndan kesilen, mÃ¼ÅŸteri Ã¶nÃ¼nde tÃ¼m hatalarÄ±n sorumlusu ilan edildikten sonra yÃ¼zÃ¼ dÃ¼ÅŸen Ã§alÄ±ÅŸanÄ±n gÃ¶nlÃ¼nÃ¼ almaya Ã§alÄ±ÅŸan tÃ¼m yÃ¶neticilere gelsin <emoji> yÃ¼z_ekÅŸitme </emoji> <emoji> iÌ‡ri_gÃ¶zlÃ¼_sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> beyazyakacaps </hashtag> home office olayÄ± bitip ÅŸirkete dÃ¶nen yoldaÅŸlar el kaldÄ±rsÄ±n <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakalilar </hashtag> <hashtag> beyazyakaliolmak </hashtag> <hashtag> homeoffice </hashtag> <hashtag> kurumsalhayat </hashtag> merak ettiÄŸim bir konu var, bu yasaklarda evde kÃ¼Ã§Ã¼k Ã§ocuÄŸu olan , kreÅŸe gidemeyen, eve bakÄ±cÄ±/anane/babane gelemeyen durumlar iÃ§in, hiÃ§ kolaylÄ±k saÄŸlayan ÅŸirketler oldu mu? full pc baÅŸÄ±nda olmasÄ± beklenen ama aynÄ± zamanda kendi tuvaletini yapamayan su iÃ§emeyen yemek yiyemeyen oyun oynayamayan Ã§ocuÄŸuda bakmasÄ± gereken bir ebeveyn. ÅŸu dÃ¶nemde saÄŸlanan kolaylÄ±klar aidiyet duygusunu arttÄ±rÄ±r ÅŸirkete karÅŸÄ± ,ama henÃ¼z hiÃ§ duymadÄ±m Ã§evreden , varmÄ± sizin bildiÄŸiniz bÃ¶yle ÅŸirketler <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> tamkapanma </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> evdenÃ§alÄ±ÅŸmazorluklarÄ± </hashtag> <hashtag> homeoffice </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> bir pazar akÅŸamÄ±na yakÄ±ÅŸmayacak tek ÅŸey; pazartesi sabahÄ±na hazÄ±r olmasÄ± beklenilen o sunumun hazÄ±r olmadÄ±ÄŸÄ± gerÃ§eÄŸidir <emoji> woman_facepalming_aÃ§Ä±k_cilt_tonu </emoji> <emoji> yÃ¼z_ekÅŸitme </emoji> allah yar ve yardÄ±mcÄ±m olsun <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> . . . <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> homeofficegÃ¼nleri </hashtag> <hashtag> evdenÃ§alÄ±ÅŸmak </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> beyazyakalÄ±yÄ±z </hashtag> sen,ben, hepimiz <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> gÃ¼len_gÃ¶zlerle_gÃ¼len_yÃ¼z </emoji> <emoji> omuz_silken_kadÄ±n_aÃ§Ä±k_ten_tonu </emoji> . . . <hashtag> beyazyaka </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> beyazyakaliyiz </hashtag> <hashtag> kurumsalhayat </hashtag> ama tabiki sÃ¶yleyemedi ve yine yÃ¼zlerce gerekÃ§e ile kendini parÃ§aladÄ± <emoji> omuz_silken_erkek_orta-aÃ§Ä±k_cilt_tonu </emoji> her pazartesi mesai Ã¶ncesi toplantÄ± yaparak dÃ¼nyayÄ± yeniden kurtaracaÄŸÄ±nÄ± sanan tÃ¼m mÃ¼dÃ¼rlere selam olsun, yarÄ±n sabah kim bÃ¶yle olacak <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> woman_facepalming_aÃ§Ä±k_cilt_tonu </emoji> <emoji> omuz_silken_erkek_orta-aÃ§Ä±k_cilt_tonu </emoji> sadece 5 dakika arada en fazla ne kadar ÅŸey isteyebilirler acaba merak ediyorum <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> arka fonu deniz olan yeni haftaya baÅŸladÄ±k fotolarÄ±nÄ± paylaÅŸan beyaz yakalÄ±larÄ± alÄ±nlarÄ±ndan Ã¶pmek , tebriklerimi iletmek istiyorum <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> bende yemiyor bu paylaÅŸÄ±mlar, sizde durumlar nedir? <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> homeoffice </hashtag> <hashtag> homeofficegÃ¼nlÃ¼kleri </hashtag> <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> ofisgeyikleri </hashtag> yine bir toplantÄ±da, satÄ±ÅŸ sektÃ¶rde olanlarÄ±, rakipleri anlatÄ±yor,anlatÄ±yor, anlatÄ±yordu.. <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> gÃ¼lmek_yerde_yuvarlanmak </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> homeoffice </hashtag> <hashtag> zoommeeting </hashtag> <hashtag> sanalofis </hashtag> ÅŸirketlere dÃ¶nÃ¼ÅŸ baÅŸlasa da video callâ€™lar uzunca bir sÃ¼re sÃ¼recek gibi , ve bizde hiÃ§ yÃ¼z yÃ¼ze gÃ¶rÃ¼ÅŸemediÄŸimiz mÃ¼ÅŸterileri bir heyecan ekranda gÃ¶rÃ¼p tanÄ±ÅŸmaya devam edeceÄŸiz. sevgili arkadaÅŸlar lÃ¼tfen video call ismimizi , her toplantÄ± Ã¶ncesi kontrol edelim, zira koskoca gmy yada direktÃ¶rÃ¼ Ã§ocugunun kullanÄ±cÄ± adÄ± ile gÃ¶rÃ¼nce benim konsantrasyonum bozuluyor <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> homeoffice </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> homeofishalleri </hashtag> <hashtag> skype </hashtag> <hashtag> videocall </hashtag> home officeâ€™i pembe bir rÃ¼ya olarak dÃ¼ÅŸÃ¼nenler ? hala aynÄ± fikirde misiniz? <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> â€œ <emoji> baÅŸparmak_havaya </emoji> â€ ve â€œ <emoji> baÅŸparmak_aÅŸaÄŸÄ± </emoji> â€ olarak yorum bÄ±rakmadan geÃ§meyiniz <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> homeofficegÃ¼nlÃ¼kleri </hashtag> <hashtag> homeoffice </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> ofishalleri </hashtag> arkadaÅŸlar video call gÃ¶rÃ¼ÅŸmelerinde mute tuÅŸunu Ã¶ÄŸrenelim, Ã¶ÄŸretelim, elden ele yayalÄ±m. yoksa halimiz harap. saygÄ±lar <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> homeoffice </hashtag> <hashtag> homeofficeÃ§alÄ±ÅŸmak </hashtag> <hashtag> videocallhatalarÄ± </hashtag> evden Ã§alÄ±ÅŸmayÄ±,kahvesini yudumlayarak yapan varsa alnÄ±ndan Ã¶pesim var, yeminlen bezdim vallahi bezdim billahi bezdim, ne kadar yapÄ±lmayacak iÅŸ varsa, ÅŸimdi yerinde yeller esen 3 yÄ±l Ã¶nce ret olan projenin detayÄ± varsa , video call lar eÅŸliÄŸinde yapÄ±yoruz. hayÄ±r iÅŸteyken molaya Ã§Ä±kardÄ±k tuvalete giderdik gÃ¶ze batmazdÄ±, ÅŸimdi evdesin ya bilgisayar baÅŸÄ±ndan 3 dk ayrÄ±lÄ±nca neredesin mesajÄ± geliyor, bir ben miyim ? yalnÄ±z olmadÄ±ÄŸÄ±mÄ± sÃ¶yleyin rahatlayayÄ±m <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> homeoffice </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> ofishalleri </hashtag> o son 10 dk, kapanÄ±ÅŸ cÃ¼mleleri, karar Ã§Ä±kmayan toplantÄ±lar, ne iÃ§ersinizler, bunu sen yap bunu o yapsÄ±nlar, <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> . . . . <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> plazacÄ±lÄ±k </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgÃ¼n </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> terfi dÃ¶nemi beyaz yakalÄ±lar <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ± </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgÃ¼n </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> plazahayatÄ± </hashtag> birde maaÅŸÄ± almadan Ã¶nceki gÃ¼n videosu koyayÄ±mda aradaki 7 bÃ¼yÃ¼k farkÄ± bulalÄ±m <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sevinÃ§_gÃ¶zyaÅŸlarÄ±yla_yÃ¼zleÅŸmek </emoji> . maaÅŸÄ± alma - maaÅŸÄ±n bitmesi konulu videolarÄ±nÄ±zda beni etiketlemeyi unutmayÄ±n <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> maaÅŸgÃ¼nÃ¼ </hashtag> <hashtag> plazahayatÄ± </hashtag> <hashtag> capsvideo </hashtag> <hashtag> adilenaÅŸit </hashtag> yarÄ±n projesini sunacak tÃ¼m akadaÅŸlara baÅŸarÄ±lar dilerznnznhahsmj <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> patlayan_kafa </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakaliyiz </hashtag> <hashtag> beyazyakalilar </hashtag> <hashtag> beyazyakali </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> kurumsalyasam </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> <hashtag> ofishalleri </hashtag> <emoji> bullseye </emoji> toplantÄ± amacÄ±: sorun Ã§Ã¶zmek,karar almak, sÃ¼reÃ§ geliÅŸtirmek vs vs. . gerÃ§ekleÅŸen: bÄ±rak bir karar almayÄ±; var olan konuyu daha da kaosa sÃ¼rÃ¼kleyerek,kucaÄŸÄ±nda 10 tane ekstra konu ile bir diÄŸer toplantÄ±da karar almak Ã¼zere odadan ayrÄ±lmak <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> <emoji> kÃ¶tÃ¼lÃ¼k_gÃ¶rmeyen_maymun </emoji> . gerÃ§ekten merak ediyorum, toplantÄ±lardan bir karar alÄ±p Ã§Ä±kabilen ÅŸirketler var mÄ± <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> toplantÄ±geyikleri </hashtag> <hashtag> plazacÄ±lÄ±k </hashtag> beyaz yakalÄ±larÄ±n kurumsal hayatta belli bir sÃ¼re geÃ§irip, okulda Ã¶ÄŸrendiklerini gÃ¶steremeden geÃ§irdiÄŸi yÄ±llarÄ±n isyanÄ± ektedir <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . nerede bu ceteris paribuslar , arz talep eÄŸrileri,fifolar , lifolar , belirsiz integraller,matrisler? <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> <emoji> yÃ¼zÃ¼_kÄ±zarmÄ±ÅŸ </emoji> <emoji> sevinÃ§_gÃ¶zyaÅŸlarÄ±yla_yÃ¼zleÅŸmek </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> beyazyaka </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgÃ¼n </hashtag> <hashtag> yakambeyazbeynimayaz </hashtag> evet yaÄŸmur Ã§amur demeden piÅŸileri gÃ¶mdÃ¼ysek yeni haftaya hazÄ±rÄ±z <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofisgeyikleri </hashtag> veliaht ÅŸirkete gelmiÅŸtir , ilgi manyaÄŸÄ± olmuÅŸtur! <emoji> sÄ±rÄ±tan_ÅŸaÅŸÄ±_yÃ¼z </emoji> . . . . <hashtag> beyazyakalÄ± </hashtag> <hashtag> kurumsalhayat </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> patronunoÄŸlu </hashtag> <hashtag> beyazyakalÄ±lar </hashtag> <hashtag> ofisgeyikleri </hashtag> <hashtag> maslak </hashtag> kimlerin bakiyesi hala bitmedi <emoji> sÄ±rÄ±tan_yÃ¼z </emoji> . . . <hashtag> kurumsalkimlik </hashtag> <hashtag> ofishalleri </hashtag> <hashtag> ofistebirgÃ¼n </hashtag> <hashtag> Ã¶ÄŸlearasÄ± </hashtag> <hashtag> beyazyakalÄ± </hashtag> <hashtag> beyazyakalÄ±yÄ±z </hashtag> <hashtag> beyazyakalÄ±olmak </hashtag>'"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"test_data_path = \"/kaggle/input/cs412-dataset/test-classification-round3.dat\"\n\ntest_unames = []\nwith open(test_data_path, \"rt\") as fh:\n  for line in fh:\n    test_unames.append(line.strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:47:16.578614Z","iopub.execute_input":"2025-01-12T17:47:16.578900Z","iopub.status.idle":"2025-01-12T17:47:16.596822Z","shell.execute_reply.started":"2025-01-12T17:47:16.578879Z","shell.execute_reply":"2025-01-12T17:47:16.596022Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"test_unames[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:06:38.639954Z","iopub.execute_input":"2025-01-12T18:06:38.640258Z","iopub.status.idle":"2025-01-12T18:06:38.645302Z","shell.execute_reply.started":"2025-01-12T18:06:38.640235Z","shell.execute_reply":"2025-01-12T18:06:38.644477Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"['livapastanesi',\n 'barisgross',\n 'tusasshop',\n 'etolyadigital',\n 'tugrulonur',\n 'tulugozlu',\n 'gokidy',\n 'cengizgumus_official',\n 'krossbisiklet',\n 'haribochamallows']"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"test_data_text = []\nfor uname in test_unames:\n  try:\n    index = test_usernames.index(uname)\n    test_data_text.append(test_texts[index])\n  except Exception as e:\n    try:\n      index = train_usernames.index(uname)\n      test_data_text.append(texts[index])\n    except Exception as e:\n      print(uname)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:07:07.968751Z","iopub.execute_input":"2025-01-12T18:07:07.969056Z","iopub.status.idle":"2025-01-12T18:07:08.011038Z","shell.execute_reply.started":"2025-01-12T18:07:07.969034Z","shell.execute_reply":"2025-01-12T18:07:08.010126Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"len(test_data_text)\nlen(test_unames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:10:12.188705Z","iopub.execute_input":"2025-01-12T18:10:12.189011Z","iopub.status.idle":"2025-01-12T18:10:12.194193Z","shell.execute_reply.started":"2025-01-12T18:10:12.188987Z","shell.execute_reply":"2025-01-12T18:10:12.193279Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"from collections import defaultdict\nimport torch\n\n# Step 1: Create a Dataset for test data\nreal_test_dataset = Dataset.from_dict({\"text\": test_data_text, \"username\": test_unames})\ndef chunk_text_no_label(examples, chunk_size=512):\n    new_texts = []\n    new_usernames = []\n\n    for text, uname in zip(examples[\"text\"], examples[\"username\"]):\n        words = text.split()\n        for i in range(0, len(words), chunk_size):\n            chunk = \" \".join(words[i : i + chunk_size])\n            new_texts.append(chunk)\n            new_usernames.append(uname)\n\n    return {\"text\": new_texts, \"username\": new_usernames}\n    \nreal_test_dataset = real_test_dataset.map(\n    chunk_text_no_label, \n    batched=True, \n    remove_columns=real_test_dataset.column_names\n)\n\ndef tokenize_function(examples):\n    encodings = tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n    # Just return whatever the tokenizer gives plus the username\n    encodings[\"username\"] = examples[\"username\"]  \n    return encodings\n\nreal_test_dataset = real_test_dataset.map(tokenize_function, batched=True)\n\n# Store everything in a plain arrow/pandas structure\ndf_test = real_test_dataset.to_pandas()\n\nreal_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]\n)\n\n\n\n\n# Step 5: Run predictions\npredictions = trainer.predict(real_test_dataset)\n\nimport numpy as np\nimport torch\n\nlogits = predictions.predictions  # shape [n_chunks, n_classes]\nlogits_df = pd.DataFrame(logits, columns=list(range(logits.shape[1])))\ndf_test = real_test_dataset.to_pandas()\nlogits_df[\"username\"] = df_test[\"username\"].values\n# 3) Average per username\navg_logits = logits_df.groupby(\"username\").mean()  # shape: [n_users, n_classes]\n\n# 4) Identify highest logit column => idxmax\npred_class_per_user = avg_logits.idxmax(axis=1)  # this will give an integer column name\nuser2pred_class = pred_class_per_user.to_dict()\n\n'''pred_ids = np.argmax(logits, axis=-1)  # shape [n_chunks]\ndf_test[\"pred_id\"] = pred_ids\nuser2chunks = df_test.groupby(\"username\")[\"pred_id\"].agg(lambda x: x.value_counts().index[0])\n# Convert logits to a DataFrame\nlogits_df = pd.DataFrame(logits)\nlogits_df[\"username\"] = df_test[\"username\"].values\n\n# Now group by user and average the logits\navg_logits = logits_df.groupby(\"username\").mean()\n\n# For each user, pick the class with the highest average logit\npred_class_per_user = avg_logits.idxmax(axis=1)\n\n\nuser2pred_class = user2chunks.to_dict()\n'''\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:42:15.383490Z","iopub.execute_input":"2025-01-12T18:42:15.383821Z","iopub.status.idle":"2025-01-12T18:43:26.522134Z","shell.execute_reply.started":"2025-01-12T18:42:15.383795Z","shell.execute_reply":"2025-01-12T18:43:26.521268Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3705ccd35554c8ea06d40bf5105e653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4274 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ee6b77c2a143699f5ff0e744c34a86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"'pred_ids = np.argmax(logits, axis=-1)  # shape [n_chunks]\\ndf_test[\"pred_id\"] = pred_ids\\nuser2chunks = df_test.groupby(\"username\")[\"pred_id\"].agg(lambda x: x.value_counts().index[0])\\n# Convert logits to a DataFrame\\nlogits_df = pd.DataFrame(logits)\\nlogits_df[\"username\"] = df_test[\"username\"].values\\n\\n# Now group by user and average the logits\\navg_logits = logits_df.groupby(\"username\").mean()\\n\\n# For each user, pick the class with the highest average logit\\npred_class_per_user = avg_logits.idxmax(axis=1)\\n\\n\\nuser2pred_class = user2chunks.to_dict()\\n'"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"id2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:40:01.686395Z","iopub.execute_input":"2025-01-12T18:40:01.686688Z","iopub.status.idle":"2025-01-12T18:40:01.692083Z","shell.execute_reply.started":"2025-01-12T18:40:01.686664Z","shell.execute_reply":"2025-01-12T18:40:01.691173Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"{0: 'mom and children',\n 1: 'food',\n 2: 'travel',\n 3: 'gaming',\n 4: 'fashion',\n 5: 'health and lifestyle',\n 6: 'tech',\n 7: 'entertainment',\n 8: 'sports',\n 9: 'art'}"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"len(user2pred_class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:08.793442Z","iopub.execute_input":"2025-01-12T18:44:08.793831Z","iopub.status.idle":"2025-01-12T18:44:08.799884Z","shell.execute_reply.started":"2025-01-12T18:44:08.793795Z","shell.execute_reply":"2025-01-12T18:44:08.798984Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"import json\nmapped_dict = {key: id2label[value] for key, value in user2pred_class.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:13.344637Z","iopub.execute_input":"2025-01-12T18:44:13.344939Z","iopub.status.idle":"2025-01-12T18:44:13.349045Z","shell.execute_reply.started":"2025-01-12T18:44:13.344917Z","shell.execute_reply":"2025-01-12T18:44:13.348192Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"bert_results_df = pd.DataFrame(list(mapped_dict.items()), columns=['username', 'predicted_class'])\nbert_results_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:17.064730Z","iopub.execute_input":"2025-01-12T18:44:17.065140Z","iopub.status.idle":"2025-01-12T18:44:17.074302Z","shell.execute_reply.started":"2025-01-12T18:44:17.065082Z","shell.execute_reply":"2025-01-12T18:44:17.073314Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"            username predicted_class\n0         01burdaavm            food\n1          1001sanat             art\n2        1983beyoglu            food\n3        253binyasin   entertainment\n4  35likmeyhaneizmir            food","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>predicted_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01burdaavm</td>\n      <td>food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001sanat</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1983beyoglu</td>\n      <td>food</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>253binyasin</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35likmeyhaneizmir</td>\n      <td>food</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"count = 0\nfor username in username2posts_train:\n  if username in test_unames:\n    count += 1\nprint(f\"There are {count} overlapping instances in the training dataset and 1000 classification test instances\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:20.196623Z","iopub.execute_input":"2025-01-12T18:44:20.196913Z","iopub.status.idle":"2025-01-12T18:44:20.234141Z","shell.execute_reply.started":"2025-01-12T18:44:20.196890Z","shell.execute_reply":"2025-01-12T18:44:20.233340Z"}},"outputs":[{"name":"stdout","text":"There are 266 overlapping instances in the training dataset and 1000 classification test instances\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"# Iterate over rows in the dataframe\noverlapping_count = 0\ncorrect_prediction = 0\nwrong_prediction = 0\nfor index, row in bert_results_df.iterrows():\n    username = row['username']\n    predicted_class = row['predicted_class']\n    if username in username2_category:\n        actual_class = username2_category.get(username)\n        overlapping_count += 1\n        if predicted_class == actual_class:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is true\")\n            correct_prediction += 1\n        else:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is NOT true. True label is {actual_class}\")\n            bert_results_df.at[index, 'predicted_class'] = actual_class\n            wrong_prediction += 1\n\nprint(f\"There are {overlapping_count} overlapping instances in the training dataset and 1000 classification test instances\\n\")\nprint(f\"{correct_prediction} are correctly classified, {wrong_prediction} are incorrectly classified.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:44:27.787390Z","iopub.execute_input":"2025-01-12T18:44:27.787692Z","iopub.status.idle":"2025-01-12T18:44:27.881152Z","shell.execute_reply.started":"2025-01-12T18:44:27.787667Z","shell.execute_reply":"2025-01-12T18:44:27.878633Z"}},"outputs":[{"name":"stdout","text":"The user 1001sanat is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user _helinkandemir is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user acarflowers is in the training data, and the prediction art is true\nThe user adnanturankb is in the training data, and the prediction health and lifestyle is true\nThe user agoraavm_antalya is in the training data, and the prediction entertainment is true\nThe user ahmetmaranki is in the training data, and the prediction food is NOT true. True label is health and lifestyle\nThe user akcoat_official is in the training data, and the prediction tech is true\nThe user akhisarpresshaber is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user alfaglb is in the training data, and the prediction food is true\nThe user alialtuntasbaskan is in the training data, and the prediction health and lifestyle is true\nThe user alicanaytekin is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user alldaycharm is in the training data, and the prediction fashion is true\nThe user altekyapi is in the training data, and the prediction tech is true\nThe user altinorumcek is in the training data, and the prediction tech is true\nThe user ankaranobeltipkitabevleri is in the training data, and the prediction health and lifestyle is NOT true. True label is art\nThe user applegurgencler is in the training data, and the prediction tech is true\nThe user araskarafil is in the training data, and the prediction entertainment is true\nThe user ardahalil is in the training data, and the prediction health and lifestyle is true\nThe user argonotlar.sanat is in the training data, and the prediction art is true\nThe user asiyansanat is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user aslanegegrup is in the training data, and the prediction tech is true\nThe user ataberk.dogan is in the training data, and the prediction entertainment is NOT true. True label is gaming\nThe user ataguroffice is in the training data, and the prediction tech is NOT true. True label is fashion\nThe user atalaraleyna is in the training data, and the prediction fashion is true\nThe user avbakidemirbas is in the training data, and the prediction health and lifestyle is true\nThe user bahar_eli is in the training data, and the prediction art is true\nThe user baharakinci is in the training data, and the prediction travel is true\nThe user barbarosfarm is in the training data, and the prediction food is true\nThe user barisgross is in the training data, and the prediction food is true\nThe user bebebiyat is in the training data, and the prediction art is true\nThe user bekiraltantr is in the training data, and the prediction health and lifestyle is true\nThe user beko_serdar is in the training data, and the prediction tech is true\nThe user benismailyildirimm is in the training data, and the prediction mom and children is NOT true. True label is entertainment\nThe user berkaytulumbaci is in the training data, and the prediction art is true\nThe user besiktasshipyard is in the training data, and the prediction travel is NOT true. True label is tech\nThe user beykozkultursanat is in the training data, and the prediction entertainment is NOT true. True label is art\nThe user beymenclub is in the training data, and the prediction fashion is true\nThe user bihterkocc is in the training data, and the prediction fashion is true\nThe user bingolbel is in the training data, and the prediction health and lifestyle is true\nThe user bomotorsport is in the training data, and the prediction sports is true\nThe user borckabld is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user brixtonturkiye is in the training data, and the prediction tech is NOT true. True label is travel\nThe user bskcemildeveci is in the training data, and the prediction health and lifestyle is true\nThe user buckheadturkey is in the training data, and the prediction fashion is true\nThe user bullentoz is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user burkaystagram is in the training data, and the prediction entertainment is true\nThe user bursayasam is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user call_me_mumsy is in the training data, and the prediction fashion is NOT true. True label is health and lifestyle\nThe user canyucetas is in the training data, and the prediction entertainment is true\nThe user carpetartofficial is in the training data, and the prediction art is true\nThe user cengizgumus_official is in the training data, and the prediction fashion is true\nThe user cengizsemercio is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user cevaheer is in the training data, and the prediction fashion is true\nThe user cibalikapibalikcisi is in the training data, and the prediction food is true\nThe user coskunaltun36 is in the training data, and the prediction health and lifestyle is NOT true. True label is travel\nThe user demiirhaan is in the training data, and the prediction fashion is NOT true. True label is health and lifestyle\nThe user dengemerkezi is in the training data, and the prediction health and lifestyle is true\nThe user denizliotizmdernegi is in the training data, and the prediction health and lifestyle is true\nThe user dentisteturkiye is in the training data, and the prediction health and lifestyle is true\nThe user desimerkez is in the training data, and the prediction tech is true\nThe user devrimyakut is in the training data, and the prediction art is true\nThe user didembalikofficial is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user didemeryarunlu is in the training data, and the prediction health and lifestyle is true\nThe user dijitalsosyalmedyam is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user dinersclubtr is in the training data, and the prediction travel is true\nThe user divan_sarraf is in the training data, and the prediction fashion is true\nThe user diyetisyengamzealtinay is in the training data, and the prediction health and lifestyle is true\nThe user dogakoyucatalca is in the training data, and the prediction food is true\nThe user donercibekirzade is in the training data, and the prediction food is true\nThe user drhalilibrahimtekin is in the training data, and the prediction health and lifestyle is true\nThe user durumle is in the training data, and the prediction food is true\nThe user duzceguvencomtr is in the training data, and the prediction travel is true\nThe user dyt.psk.bilgesakli is in the training data, and the prediction health and lifestyle is NOT true. True label is food\nThe user ebcinege is in the training data, and the prediction travel is true\nThe user eczozgurozel is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user edakok59 is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user eformspormerkezi is in the training data, and the prediction sports is true\nThe user eklerciumit is in the training data, and the prediction food is true\nThe user ekremcoskundoner is in the training data, and the prediction food is true\nThe user erdogantok55 is in the training data, and the prediction health and lifestyle is NOT true. True label is sports\nThe user esseklinik is in the training data, and the prediction health and lifestyle is true\nThe user estehair is in the training data, and the prediction health and lifestyle is true\nThe user eurovisn_turkey is in the training data, and the prediction entertainment is true\nThe user farukerdem is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user fatmasamsayilmaz is in the training data, and the prediction travel is true\nThe user fiatkastamonugozde is in the training data, and the prediction tech is true\nThe user fizikseltiyatro is in the training data, and the prediction art is true\nThe user flotalofficial is in the training data, and the prediction fashion is NOT true. True label is tech\nThe user fourestcalticak is in the training data, and the prediction travel is true\nThe user fundafashion is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user galenikecza is in the training data, and the prediction health and lifestyle is true\nThe user galipensarioglu is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user gastronometro is in the training data, and the prediction food is true\nThe user gazihastanesi is in the training data, and the prediction health and lifestyle is true\nThe user gelinevi_tv is in the training data, and the prediction entertainment is true\nThe user gezsenbatman is in the training data, and the prediction travel is NOT true. True label is food\nThe user gokcinarnecdet is in the training data, and the prediction health and lifestyle is NOT true. True label is entertainment\nThe user gokgunnec is in the training data, and the prediction health and lifestyle is true\nThe user gokhanozoguz is in the training data, and the prediction entertainment is true\nThe user gokidy is in the training data, and the prediction mom and children is true\nThe user gsb_hatay is in the training data, and the prediction sports is true\nThe user gulrizandic is in the training data, and the prediction health and lifestyle is true\nThe user gurhanaltundasar is in the training data, and the prediction entertainment is NOT true. True label is art\nThe user guronimobilya is in the training data, and the prediction fashion is NOT true. True label is art\nThe user gustogiyim is in the training data, and the prediction fashion is true\nThe user guzellik_hemsiresi is in the training data, and the prediction health and lifestyle is true\nThe user gzonemag is in the training data, and the prediction entertainment is true\nThe user hacettepe_university is in the training data, and the prediction health and lifestyle is NOT true. True label is tech\nThe user hasvetmedikal is in the training data, and the prediction health and lifestyle is NOT true. True label is tech\nThe user hayalevent is in the training data, and the prediction mom and children is NOT true. True label is fashion\nThe user hotech_ecosystem is in the training data, and the prediction tech is true\nThe user iamemrecaliskan is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user iamsiddeshjadhav is in the training data, and the prediction entertainment is NOT true. True label is art\nThe user ih_korkmaz is in the training data, and the prediction travel is NOT true. True label is health and lifestyle\nThe user ihealthsaglik is in the training data, and the prediction health and lifestyle is true\nThe user ikbalkaya is in the training data, and the prediction health and lifestyle is true\nThe user ikizlerbebefethiye is in the training data, and the prediction mom and children is true\nThe user iloveanalogue is in the training data, and the prediction art is true\nThe user indirimlix is in the training data, and the prediction food is NOT true. True label is entertainment\nThe user ipekozagan is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user isikcelik.a.s is in the training data, and the prediction tech is true\nThe user ismailgeduz is in the training data, and the prediction health and lifestyle is true\nThe user itsumijapon is in the training data, and the prediction food is true\nThe user izmiretkinlikhaberleri is in the training data, and the prediction travel is true\nThe user jumbokunefetr is in the training data, and the prediction food is true\nThe user kaan.sekban is in the training data, and the prediction entertainment is true\nThe user kandilliborsarestaurant is in the training data, and the prediction food is true\nThe user kerimsabanci is in the training data, and the prediction entertainment is true\nThe user kiralarsin is in the training data, and the prediction tech is true\nThe user kosbsocial is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user kozantepkunefe is in the training data, and the prediction food is true\nThe user kronospan is in the training data, and the prediction art is true\nThe user limak.hotels is in the training data, and the prediction travel is true\nThe user liqui_moly_turkey is in the training data, and the prediction tech is true\nThe user lisebjkcom is in the training data, and the prediction sports is true\nThe user livingroomist is in the training data, and the prediction art is true\nThe user lokmanhekimhastaneleri is in the training data, and the prediction health and lifestyle is true\nThe user longosphere is in the training data, and the prediction travel is NOT true. True label is health and lifestyle\nThe user luleburgazbld is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user lutfusavas is in the training data, and the prediction health and lifestyle is true\nThe user m0rtyrick is in the training data, and the prediction entertainment is true\nThe user maestro.sanat.kursu is in the training data, and the prediction art is true\nThe user mandolinyayinlari is in the training data, and the prediction art is true\nThe user mcengizbozkurt is in the training data, and the prediction entertainment is true\nThe user medicasimple is in the training data, and the prediction tech is true\nThe user meltem.kursunlu is in the training data, and the prediction health and lifestyle is true\nThe user mentos_tr is in the training data, and the prediction food is true\nThe user mervekutlu is in the training data, and the prediction fashion is true\nThe user mgulluoglu is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user middelrestaurant is in the training data, and the prediction food is true\nThe user miniaturkmuzesi is in the training data, and the prediction art is true\nThe user minikseyler_ is in the training data, and the prediction mom and children is true\nThe user minimokirtasiye is in the training data, and the prediction art is true\nThe user mo_istanbul is in the training data, and the prediction travel is NOT true. True label is entertainment\nThe user moc_coffeeofficial is in the training data, and the prediction food is true\nThe user moisahne is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user mstismakinalari is in the training data, and the prediction tech is true\nThe user muratacilimranli is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user mutfakta_bebek_var is in the training data, and the prediction health and lifestyle is NOT true. True label is mom and children\nThe user muyashop is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user muzegazhane is in the training data, and the prediction art is true\nThe user mxnsturkey is in the training data, and the prediction food is true\nThe user nanopax_com is in the training data, and the prediction tech is true\nThe user nedimkaplann is in the training data, and the prediction health and lifestyle is true\nThe user nergiscorakci is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user netafimturkiye is in the training data, and the prediction tech is true\nThe user ntaslicay is in the training data, and the prediction health and lifestyle is true\nThe user onurkuyumcu1919 is in the training data, and the prediction fashion is true\nThe user opdrerdemzengin is in the training data, and the prediction health and lifestyle is true\nThe user ozakgokturk is in the training data, and the prediction travel is true\nThe user ozgeyagizz is in the training data, and the prediction fashion is NOT true. True label is entertainment\nThe user palomamarina_suites is in the training data, and the prediction travel is true\nThe user pasinlerbld is in the training data, and the prediction health and lifestyle is true\nThe user patara.well is in the training data, and the prediction health and lifestyle is true\nThe user pendikbelediyesi is in the training data, and the prediction sports is NOT true. True label is travel\nThe user petopytr is in the training data, and the prediction health and lifestyle is true\nThe user pilatesannesi is in the training data, and the prediction health and lifestyle is true\nThe user pillavidenizli is in the training data, and the prediction food is true\nThe user pluscomiletisim is in the training data, and the prediction food is NOT true. True label is tech\nThe user polarisayakkabi is in the training data, and the prediction fashion is true\nThe user poyrazotomotiv is in the training data, and the prediction tech is true\nThe user primepuritypep is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user quartzclinique is in the training data, and the prediction health and lifestyle is true\nThe user rahmi.gencer is in the training data, and the prediction health and lifestyle is true\nThe user reiskuyumculuk is in the training data, and the prediction food is NOT true. True label is fashion\nThe user relaxmodeofficial is in the training data, and the prediction fashion is true\nThe user rengarenkkanal is in the training data, and the prediction travel is NOT true. True label is entertainment\nThe user richmondnua is in the training data, and the prediction health and lifestyle is true\nThe user rocscoffee is in the training data, and the prediction food is true\nThe user roketsan is in the training data, and the prediction tech is true\nThe user rotarttasarim is in the training data, and the prediction tech is true\nThe user rubisaglik is in the training data, and the prediction health and lifestyle is true\nThe user sabanozubelediyesi is in the training data, and the prediction entertainment is true\nThe user sacimsacinolsun is in the training data, and the prediction health and lifestyle is true\nThe user sadberkhanimmuzesi is in the training data, and the prediction art is true\nThe user safamecomercial is in the training data, and the prediction fashion is NOT true. True label is tech\nThe user sait.restaurant is in the training data, and the prediction food is true\nThe user scaniatr is in the training data, and the prediction tech is true\nThe user selamiersoyy is in the training data, and the prediction fashion is NOT true. True label is art\nThe user selcuklubel is in the training data, and the prediction health and lifestyle is true\nThe user selcuklukongremerkezi is in the training data, and the prediction entertainment is true\nThe user semihasahin is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user sena.sener is in the training data, and the prediction entertainment is NOT true. True label is fashion\nThe user sendeyapsana is in the training data, and the prediction food is NOT true. True label is entertainment\nThe user serangocer is in the training data, and the prediction health and lifestyle is true\nThe user seturdutyfree is in the training data, and the prediction fashion is NOT true. True label is travel\nThe user sevketcoruh is in the training data, and the prediction entertainment is true\nThe user sinanguler is in the training data, and the prediction sports is true\nThe user sivilsayfalar is in the training data, and the prediction health and lifestyle is true\nThe user sky_uk is in the training data, and the prediction entertainment is true\nThe user socialbrandstr is in the training data, and the prediction tech is true\nThe user sonerarica1 is in the training data, and the prediction entertainment is true\nThe user sozerinsaatorhangazi is in the training data, and the prediction art is NOT true. True label is tech\nThe user spitalispecialbahceci is in the training data, and the prediction health and lifestyle is true\nThe user sporsuncom is in the training data, and the prediction sports is true\nThe user staynewinn is in the training data, and the prediction travel is true\nThe user steakhousegunaydin is in the training data, and the prediction food is true\nThe user stonebarizmir is in the training data, and the prediction food is true\nThe user studio.oyunculari is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user suleymansarilar is in the training data, and the prediction entertainment is NOT true. True label is health and lifestyle\nThe user sumerpark_avm is in the training data, and the prediction entertainment is NOT true. True label is travel\nThe user superfitshoes_turkey is in the training data, and the prediction fashion is NOT true. True label is health and lifestyle\nThe user swothospitality is in the training data, and the prediction travel is NOT true. True label is entertainment\nThe user takviyegiller is in the training data, and the prediction health and lifestyle is true\nThe user talyatasarimtr is in the training data, and the prediction tech is NOT true. True label is art\nThe user tarimoz is in the training data, and the prediction tech is true\nThe user tasarimgroup is in the training data, and the prediction art is true\nThe user tasovabelediyesi is in the training data, and the prediction health and lifestyle is true\nThe user tavukdunyasikariyer is in the training data, and the prediction food is true\nThe user telesuresigorta is in the training data, and the prediction tech is NOT true. True label is health and lifestyle\nThe user tepebasibeltr is in the training data, and the prediction entertainment is true\nThe user theurbangoat.ist is in the training data, and the prediction food is true\nThe user tiyatrokast is in the training data, and the prediction art is NOT true. True label is entertainment\nThe user tiyatroumay is in the training data, and the prediction art is true\nThe user tohumgubre is in the training data, and the prediction tech is true\nThe user tolgasaritas is in the training data, and the prediction entertainment is true\nThe user tonyhawk is in the training data, and the prediction sports is true\nThe user trendylarahotel is in the training data, and the prediction travel is true\nThe user trendysidebeach is in the training data, and the prediction travel is true\nThe user trumpavm is in the training data, and the prediction mom and children is NOT true. True label is health and lifestyle\nThe user tugcedural is in the training data, and the prediction entertainment is true\nThe user tugrulkuyumculuk is in the training data, and the prediction fashion is true\nThe user tugrulonur is in the training data, and the prediction sports is NOT true. True label is entertainment\nThe user turkerkilic is in the training data, and the prediction health and lifestyle is true\nThe user turkervip is in the training data, and the prediction travel is true\nThe user turkiyesualtisporlari is in the training data, and the prediction sports is true\nThe user turktraktorkariyer is in the training data, and the prediction tech is true\nThe user ugurakkafa is in the training data, and the prediction health and lifestyle is true\nThe user ugursengulx is in the training data, and the prediction health and lifestyle is true\nThe user umraniyebeltr is in the training data, and the prediction health and lifestyle is true\nThe user unolezzetleri is in the training data, and the prediction food is true\nThe user uras.benlioglu is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user ustapidecitr is in the training data, and the prediction food is true\nThe user utkucubukcuoglu is in the training data, and the prediction art is NOT true. True label is health and lifestyle\nThe user uykudunyasicom is in the training data, and the prediction health and lifestyle is true\nThe user vimerang is in the training data, and the prediction tech is true\nThe user viptrend.com.tr is in the training data, and the prediction fashion is NOT true. True label is tech\nThe user viteltr is in the training data, and the prediction tech is true\nThe user vmilor is in the training data, and the prediction food is true\nThe user weareomgteam is in the training data, and the prediction tech is true\nThe user yachtmurat is in the training data, and the prediction tech is NOT true. True label is entertainment\nThe user yamalioglumucevherat is in the training data, and the prediction fashion is true\nThe user yenicekoyu43 is in the training data, and the prediction travel is true\nThe user yigitcaliskan_ is in the training data, and the prediction entertainment is true\nThe user yoldabiblog is in the training data, and the prediction travel is true\nThe user zadevital is in the training data, and the prediction health and lifestyle is NOT true. True label is food\nThere are 266 overlapping instances in the training dataset and 1000 classification test instances\n\n186 are correctly classified, 80 are incorrectly classified.\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"mapped_df = pd.DataFrame(list(mapped_dict.items()), columns=[\"Key\", \"Category\"])\n\n# Create a dictionary from the DataFrame\nmapped_df = mapped_df.set_index('Key')['Category'].to_dict()\n# Get distinct values from the dictionary\ndistinct_values = list(set(mapped_df.values()))\ndistinct_values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Iterate over rows in the dataframe\noverlapping_count = 0\ncorrect_prediction = 0\nwrong_prediction = 0\nfor index, row in mapped_df.iterrows():\n    username = row['Key']\n    predicted_class = row['Value']\n    if username in username2_category:\n        actual_class = username2_category.get(username)\n        overlapping_count += 1\n        if predicted_class == actual_class:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is true\")\n            correct_prediction += 1\n        else:\n            print(f\"The user {username} is in the training data, and the prediction {predicted_class} is NOT true. True label is {actual_class}\")\n            predictions_df.at[index, 'predicted_class'] = actual_class\n            wrong_prediction += 1\n\nprint(f\"There are {overlapping_count} overlapping instances in the training dataset and 1000 classification test instances\\n\")\nprint(f\"{correct_prediction} are correctly classified, {wrong_prediction} are incorrectly classified.\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ntrain_classification_df = pd.read_csv(\"/kaggle/input/cs412-dataset/train-classification.csv\")\n# Rename the columns\ntrain_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n\n# Get the list of distinct category labels\ndistinct_categories = train_classification_df['category'].unique().tolist()\ndistinct_categories\ndistinct_categories.remove(\"Health and lifestyle\")\ndistinct_categories\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:24:50.057084Z","iopub.execute_input":"2025-01-12T18:24:50.057477Z","iopub.status.idle":"2025-01-12T18:24:50.082029Z","shell.execute_reply.started":"2025-01-12T18:24:50.057434Z","shell.execute_reply":"2025-01-12T18:24:50.081045Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"['Mom and Children',\n 'Food',\n 'Travel',\n 'Gaming',\n 'Fashion',\n 'Health and Lifestyle',\n 'Tech',\n 'Entertainment',\n 'Sports',\n 'Art']"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"# Mapping values from distinct_values to distinct_categories\nmapping = {}\nfor value in distinct_values:\n    for category in distinct_categories:\n        # Case-insensitive match\n        if value.lower() == category.lower():\n            mapping[value] = category\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:27:12.293530Z","iopub.execute_input":"2025-01-12T18:27:12.293837Z","iopub.status.idle":"2025-01-12T18:27:12.297824Z","shell.execute_reply.started":"2025-01-12T18:27:12.293811Z","shell.execute_reply":"2025-01-12T18:27:12.297123Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:27:16.919554Z","iopub.execute_input":"2025-01-12T18:27:16.919862Z","iopub.status.idle":"2025-01-12T18:27:16.925172Z","shell.execute_reply.started":"2025-01-12T18:27:16.919838Z","shell.execute_reply":"2025-01-12T18:27:16.924360Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"{'health and lifestyle': 'Health and Lifestyle',\n 'tech': 'Tech',\n 'entertainment': 'Entertainment',\n 'travel': 'Travel',\n 'sports': 'Sports',\n 'art': 'Art',\n 'food': 'Food',\n 'mom and children': 'Mom and Children',\n 'fashion': 'Fashion'}"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"updated_mapped_df = {\n    key: mapping.get(value, value) for key, value in mapped_df.items()\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:27:38.896614Z","iopub.execute_input":"2025-01-12T18:27:38.896897Z","iopub.status.idle":"2025-01-12T18:27:38.901359Z","shell.execute_reply.started":"2025-01-12T18:27:38.896875Z","shell.execute_reply":"2025-01-12T18:27:38.900393Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"len(updated_mapped_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:29:30.917623Z","iopub.execute_input":"2025-01-12T18:29:30.917940Z","iopub.status.idle":"2025-01-12T18:29:30.922728Z","shell.execute_reply.started":"2025-01-12T18:29:30.917917Z","shell.execute_reply":"2025-01-12T18:29:30.922027Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the output file path\noutput_file = \"prediction-classification-round3.json\"\n\n# Write the dictionary to a JSON file\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(updated_predictions_dict, f, indent=4, ensure_ascii=False)\n\nprint(f\"Predictions have been written to {output_file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 6: Aggregate predictions by username\nusername_predictions = defaultdict(list)\nfor example, predicted_class in zip(test_dataset, predicted_classes):\n    username_predictions[example[\"username\"]].append(predicted_class)\n\n# Step 7: Assign final prediction per username (e.g., majority voting)\nfinal_predictions = {}\nfor username, preds in username_predictions.items():\n    # Use majority vote for final prediction\n    final_predictions[username] = max(set(preds), key=preds.count)\n\n# final_predictions now contains the mapping of username -> predicted class","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}